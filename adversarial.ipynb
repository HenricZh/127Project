{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tVYA302cLyfP"
   },
   "source": [
    "# Provable Robustness for Deep Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LbEBZGKLyfZ"
   },
   "source": [
    "In this notebook, we will implement the robustness certificate that we derived in the PDF. That is, we will first define and train a three-layer neural classifier; then, we will calculate its dual, and using this, check whether the classifier is dual at given input points.\n",
    "\n",
    "**Your task is to fill in any sections labeled TODO in the code and answer the bolded questions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJMgQYklLyfd"
   },
   "source": [
    "We are using torch here; for our purposes, we can think of torch as essentially numpy with GPU support and and automatic differentiation. That is, for any function we compute, torch automatically keeps track of the function's gradient with respect to inputs; this will make gradient descent much easier to implement. \n",
    "\n",
    "The primary object you will need to manipulate here is `torch.Tensor`, which can be thought of as equivalent to  `np.array`. Indexing, splicing, multiplication, etc. will work like you would expect them to in numpy.\n",
    "\n",
    "Also, most of the numpy functions you are used to are present in torch, with the same name. E.g:\n",
    "* `np.max(input, axis)` --> `torch.max(input, dim)` (Note that `torch.max` actually returns a tuple of the max and argmax).\n",
    "* `np.zeros` --> `torch.zeros`\n",
    "* `np.eye` --> `torch.eye`\n",
    "* `np.linalg.norm(x, ord, axis)` --> `torch.norm(input, p, dim)`\n",
    "\n",
    "For more information, refer to the [torch documentation](https://pytorch.org/docs/stable/torch.html) or the [torch tutorials](https://pytorch.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3ChNfnaLBbw"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PczgocJtLBb0"
   },
   "source": [
    "Here, we import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3oepvCSLyfi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPbnELbsLBcM"
   },
   "source": [
    "This line tells torch to use the GPU if available, and otherwise the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "hBpT1WebQ394",
    "outputId": "4316775c-297a-4541-c43c-89efc5bcb9c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awgBbuiRLyf0"
   },
   "source": [
    "Here, we load in the MNIST dataset. The inputs are $28\\times 28$ images of handwritten digits, while the labels are the corresponding digit. Note that we split the data between a training set and a test set. In order to have an unbiased estimate of the classifier's performance, we must train the model only on the training set (**never the test set**), then test its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334,
     "referenced_widgets": [
      "c33f5dd2c1f443f1b771f0c46054eebf",
      "9601fc4be35543a784d4231a2de31edb",
      "8c6d1f7d352a4c089e4ae601a73c1068",
      "3ce16927200e4dfbba645b52ede3be15",
      "8a08a24593a2422985302484dc4594d1",
      "410b4797b4eb474185b6e9e8768efe90",
      "7f3be4825b3942bfbd15404ae2826968",
      "51fab2724f5240f2a197da36bfb5d37f",
      "1e0fc65863e247bba684aa570176e47e",
      "0ffb65b8fcd64017a1575ef5c6fb6783",
      "9b0d7cc1d4a84b32ad704d0f92aaf7c2",
      "359ca0eaed76461b8920085a62f10151",
      "0d2ab5e4e4634c2d84445dcb59e63093",
      "c75be203b59b4c599fd51b44b5359236",
      "7cb630c6d3784c0ba705b39311a36690",
      "080f0e9e20374c8b9d0772c207d40204",
      "443bc19134b346e282b58b81de72ee9b",
      "be2ab404919947b6bec6e47d8ef2293e",
      "d51c1aaaee7e40eb9a6946ee964f26db",
      "75a9df895ea94bb787ead957f9b540c9",
      "40781e910ad14961b70299654d08af57",
      "48f34dff73514ae58be4a78b897605de",
      "73155d071971464cac0ed23138cde635",
      "ad74039e867d489fbcc6c9d8ff34706c",
      "bde4879694234dc087cc6ef3a8f999e4",
      "86cdc4424b24473a8d571d2160ee7576",
      "9d5649b6391e44f5ad266c65fe71ec8e",
      "2dfa9272bd3a454582ebcd023d814301",
      "68fb67ba49274e2381586dfa12d4a00a",
      "de997021a80b4943b20c5518910ea387",
      "77a3b32f508c46f4a5bae2a29bbfc4f2",
      "5cdd60a9989c4e2fba367aa0fc23db04"
     ]
    },
    "colab_type": "code",
    "id": "q58IyfpGLyf4",
    "outputId": "73cb8853-c645-4bf7-d8e5-392613148c4a"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4iXn51ILygD"
   },
   "source": [
    "This is a utility function to visualize torch Tensors as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EkoFimALygG"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    '''\n",
    "    Visualizes IMG.\n",
    "    IMG should be a 2D torch Tensor.\n",
    "    '''\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iu56FwY-LBc9"
   },
   "source": [
    "## Primal Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAc2QEcALygQ"
   },
   "source": [
    "Here, we define the neural classifier we will be using. Note that the network comprises three layers. The first layer has dimension $28^2$ since this is the size of the input image. (The original inputs are square images, but we flatten them into a $28^2\\times 1$ vector in order to feed them into the network.) The output layer has dimension $10$, since there are ten possible output classes (the digits 0-9). The hidden layer has dimension $256$. (There isn't as much science behind choosing the dimensionality of input layers; we choose $256$ because it is a round number, and is hopefully enough to the neccesary encode information about the input image.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "6-joaa2DLygU",
    "outputId": "512b7136-2b3a-4487-837d-f8b3f554f582"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.fc1 = nn.Linear(in_features=28*28, out_features = 256)\n",
    "    self.fc2 = nn.Linear(in_features=256, out_features = 10)\n",
    "    self.layers = [self.fc1, self.fc2]\n",
    "\n",
    "  # define forward function\n",
    "  def forward(self, t):\n",
    "    '''\n",
    "    On input T, performs a affine transformation, then\n",
    "    a ReLU, then another affine transformation.\n",
    "    '''\n",
    "    self.z = []\n",
    "    t = t.reshape(-1, 28*28)\n",
    "    t = self.fc1(t)\n",
    "    self.z.append(t)\n",
    "    t = F.relu(t)\n",
    "    t = self.fc2(t)\n",
    "    self.z.append(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTue7LMGLygd"
   },
   "source": [
    "Here is the training code, which uses Adam, a variant of gradient descent. The actual optimization machinery is all abstracted away behind the torch library; all the work is being done by the `optimizer.step()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zdMiOXDLygf"
   },
   "outputs": [],
   "source": [
    "def train(net, criterion, trainloader, lr=0.001):\n",
    "    '''\n",
    "    Uses the Adam optimization algorithm to train \n",
    "    the classifier NET on training data from TRAINLOADER,\n",
    "    on loss function CRITERION, with learning rate LR.\n",
    "    \n",
    "    Note that we half the learning rate each epoch.\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.5 ** (epoch)\n",
    "\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i % 500 == 0:\n",
    "                print('Epoch', epoch, 'Iter:', i, 'Loss', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmx06HSLLyhh"
   },
   "source": [
    "We can now train the net on the training data, using cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "id": "W8pmvL6tLyhj",
    "outputId": "4d4e82cf-a525-485b-914c-d1afae757338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Iter: 0 Loss 2.326780080795288\n",
      "Epoch 0 Iter: 500 Loss 0.13542862236499786\n",
      "Epoch 0 Iter: 1000 Loss 0.07145112752914429\n",
      "Epoch 0 Iter: 1500 Loss 0.44474369287490845\n",
      "Epoch 0 Iter: 2000 Loss 0.05036333575844765\n",
      "Epoch 0 Iter: 2500 Loss 0.020016632974147797\n",
      "Epoch 0 Iter: 3000 Loss 0.9844821691513062\n",
      "Epoch 0 Iter: 3500 Loss 0.17815697193145752\n",
      "Epoch 0 Iter: 4000 Loss 0.028504526242613792\n",
      "Epoch 0 Iter: 4500 Loss 0.342725545167923\n",
      "Epoch 0 Iter: 5000 Loss 0.24820786714553833\n",
      "Epoch 0 Iter: 5500 Loss 0.022639596834778786\n",
      "Epoch 0 Iter: 6000 Loss 0.49750733375549316\n",
      "Epoch 0 Iter: 6500 Loss 0.09807820618152618\n",
      "Epoch 0 Iter: 7000 Loss 0.004152089823037386\n",
      "Epoch 0 Iter: 7500 Loss 0.003874358022585511\n",
      "Epoch 0 Iter: 8000 Loss 0.5166742205619812\n",
      "Epoch 0 Iter: 8500 Loss 0.6758140325546265\n",
      "Epoch 0 Iter: 9000 Loss 0.30019721388816833\n",
      "Epoch 0 Iter: 9500 Loss 0.039654843509197235\n",
      "Epoch 0 Iter: 10000 Loss 0.0076116276904940605\n",
      "Epoch 0 Iter: 10500 Loss 0.009334434755146503\n",
      "Epoch 0 Iter: 11000 Loss 0.6482752561569214\n",
      "Epoch 0 Iter: 11500 Loss 0.8855287432670593\n",
      "Epoch 0 Iter: 12000 Loss 0.20628896355628967\n",
      "Epoch 0 Iter: 12500 Loss 0.19572938978672028\n",
      "Epoch 0 Iter: 13000 Loss 0.7103199362754822\n",
      "Epoch 0 Iter: 13500 Loss 2.0370335578918457\n",
      "Epoch 0 Iter: 14000 Loss 0.01015371922403574\n",
      "Epoch 0 Iter: 14500 Loss 0.0017463869880884886\n",
      "Epoch 1 Iter: 0 Loss 0.9441854953765869\n",
      "Epoch 1 Iter: 500 Loss 0.02817758359014988\n",
      "Epoch 1 Iter: 1000 Loss 0.014704911038279533\n",
      "Epoch 1 Iter: 1500 Loss 0.006870754994452\n",
      "Epoch 1 Iter: 2000 Loss 1.5418440103530884\n",
      "Epoch 1 Iter: 2500 Loss 0.019990820437669754\n",
      "Epoch 1 Iter: 3000 Loss 0.3987980782985687\n",
      "Epoch 1 Iter: 3500 Loss 0.0016892100684344769\n",
      "Epoch 1 Iter: 4000 Loss 0.00013533048331737518\n",
      "Epoch 1 Iter: 4500 Loss 0.04484430328011513\n",
      "Epoch 1 Iter: 5000 Loss 0.12752418220043182\n",
      "Epoch 1 Iter: 5500 Loss 0.007855191826820374\n",
      "Epoch 1 Iter: 6000 Loss 0.5046730041503906\n",
      "Epoch 1 Iter: 6500 Loss 0.02217748388648033\n",
      "Epoch 1 Iter: 7000 Loss 0.003329036058858037\n",
      "Epoch 1 Iter: 7500 Loss 0.01108931191265583\n",
      "Epoch 1 Iter: 8000 Loss 0.01607528328895569\n",
      "Epoch 1 Iter: 8500 Loss 0.13177143037319183\n",
      "Epoch 1 Iter: 9000 Loss 0.004711240995675325\n",
      "Epoch 1 Iter: 9500 Loss 0.0019232037011533976\n",
      "Epoch 1 Iter: 10000 Loss 0.0005236209835857153\n",
      "Epoch 1 Iter: 10500 Loss 0.0003134136786684394\n",
      "Epoch 1 Iter: 11000 Loss 0.0036602728068828583\n",
      "Epoch 1 Iter: 11500 Loss 0.13666586577892303\n",
      "Epoch 1 Iter: 12000 Loss 0.0007280941936187446\n",
      "Epoch 1 Iter: 12500 Loss 0.02725050412118435\n",
      "Epoch 1 Iter: 13000 Loss 2.118901102221571e-05\n",
      "Epoch 1 Iter: 13500 Loss 0.0042795748449862\n",
      "Epoch 1 Iter: 14000 Loss 0.025474825873970985\n",
      "Epoch 1 Iter: 14500 Loss 0.005018008407205343\n",
      "Epoch 2 Iter: 0 Loss 0.048590511083602905\n",
      "Epoch 2 Iter: 500 Loss 0.6477154493331909\n",
      "Epoch 2 Iter: 1000 Loss 0.176934152841568\n",
      "Epoch 2 Iter: 1500 Loss 0.005606137681752443\n",
      "Epoch 2 Iter: 2000 Loss 0.0485830120742321\n",
      "Epoch 2 Iter: 2500 Loss 0.0016429342795163393\n",
      "Epoch 2 Iter: 3000 Loss 0.0027298901695758104\n",
      "Epoch 2 Iter: 3500 Loss 0.002034396631643176\n",
      "Epoch 2 Iter: 4000 Loss 0.10932566225528717\n",
      "Epoch 2 Iter: 4500 Loss 0.0006166159873828292\n",
      "Epoch 2 Iter: 5000 Loss 0.0033483593724668026\n",
      "Epoch 2 Iter: 5500 Loss 0.009107776917517185\n",
      "Epoch 2 Iter: 6000 Loss 0.012636537663638592\n",
      "Epoch 2 Iter: 6500 Loss 0.019750406965613365\n",
      "Epoch 2 Iter: 7000 Loss 0.023298440501093864\n",
      "Epoch 2 Iter: 7500 Loss 0.01668677292764187\n",
      "Epoch 2 Iter: 8000 Loss 0.004394251387566328\n",
      "Epoch 2 Iter: 8500 Loss 0.2846784293651581\n",
      "Epoch 2 Iter: 9000 Loss 0.14413751661777496\n",
      "Epoch 2 Iter: 9500 Loss 0.16275136172771454\n",
      "Epoch 2 Iter: 10000 Loss 0.026029817759990692\n",
      "Epoch 2 Iter: 10500 Loss 0.017917301505804062\n",
      "Epoch 2 Iter: 11000 Loss 0.015345346182584763\n",
      "Epoch 2 Iter: 11500 Loss 0.020292166620492935\n",
      "Epoch 2 Iter: 12000 Loss 0.00011559053382370621\n",
      "Epoch 2 Iter: 12500 Loss 0.0006239278591237962\n",
      "Epoch 2 Iter: 13000 Loss 0.0015847648028284311\n",
      "Epoch 2 Iter: 13500 Loss 0.0022157407365739346\n",
      "Epoch 2 Iter: 14000 Loss 0.10924452543258667\n",
      "Epoch 2 Iter: 14500 Loss 0.10220994055271149\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(net, criterion, trainloader, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12zEbgnwLBdg"
   },
   "source": [
    "Let's load a sample image from the test dataset, and see what the classifier makes of it. Make sure to visualize the image using `imshow(x[0,0])`. Also, note that the line `test_iter.next()` pulls a new input image from the test set each time you run it; try running the next code block a few times to get a sense of what the MNIST dataset looks like, and how the classifier performs on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFBwByD1LBdi"
   },
   "outputs": [],
   "source": [
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "sB_m2TzpONdu",
    "outputId": "f09820e2-65df-4c6e-80fe-32432bd510b4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaqElEQVR4nO3df2xV9f3H8VeL9ILaXiylvb2jQEEFwy8ng9rwYygNtC4GtEtA/QMWAoFdzLDzx7qIKFvSjSWOuCD+s8BMxF+JQCRLMym2hNliqDDCph3tugGBFsVxbylSGP18/yDer1cKeMq9ffdeno/kJPTe8+l9ezzhyWlvT9Occ04AAPSxdOsBAAA3JwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM3GI9wLd1d3frxIkTyszMVFpamvU4AACPnHPq6OhQMBhUevrVr3P6XYBOnDihgoIC6zEAADfo2LFjGj58+FWf73dfgsvMzLQeAQAQB9f7+zxhAdq4caNGjRqlQYMGqaioSB9//PF3WseX3QAgNVzv7/OEBOjtt99WRUWF1q5dq08++USTJ0/WvHnzdOrUqUS8HAAgGbkEmDZtmguFQtGPL1265ILBoKuqqrru2nA47CSxsbGxsSX5Fg6Hr/n3fdyvgC5cuKDGxkaVlJREH0tPT1dJSYnq6+uv2L+rq0uRSCRmAwCkvrgH6IsvvtClS5eUl5cX83heXp7a2tqu2L+qqkp+vz+68Q44ALg5mL8LrrKyUuFwOLodO3bMeiQAQB+I+88B5eTkaMCAAWpvb495vL29XYFA4Ir9fT6ffD5fvMcAAPRzcb8CysjI0JQpU1RTUxN9rLu7WzU1NSouLo73ywEAklRC7oRQUVGhxYsX6wc/+IGmTZumDRs2qLOzUz/5yU8S8XIAgCSUkAAtXLhQn3/+uV544QW1tbXp3nvvVXV19RVvTAAA3LzSnHPOeohvikQi8vv91mMAAG5QOBxWVlbWVZ83fxccAODmRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMQ9QC+++KLS0tJitnHjxsX7ZQAASe6WRHzS8ePHa9euXf//Irck5GUAAEksIWW45ZZbFAgEEvGpAQApIiHfAzpy5IiCwaBGjx6tJ554QkePHr3qvl1dXYpEIjEbACD1xT1ARUVF2rJli6qrq7Vp0ya1trZq5syZ6ujo6HH/qqoq+f3+6FZQUBDvkQAA/VCac84l8gXOnDmjkSNH6uWXX9bSpUuveL6rq0tdXV3RjyORCBECgBQQDoeVlZV11ecT/u6AIUOG6O6771Zzc3OPz/t8Pvl8vkSPAQDoZxL+c0Bnz55VS0uL8vPzE/1SAIAkEvcAPf3006qrq9O///1vffTRR3rkkUc0YMAAPfbYY/F+KQBAEov7l+COHz+uxx57TKdPn9awYcM0Y8YMNTQ0aNiwYfF+KQBAEkv4mxC8ikQi8vv91mMAAG7Q9d6EwL3gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATCf+FdOhbP/7xjz2vWbZsWa9e68SJE57XnD9/3vOaN954w/OatrY2z2skXfUXJwKIP66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLNOeesh/imSCQiv99vPUbS+te//uV5zahRo+I/iLGOjo5erfv73/8e50kQb8ePH/e8Zv369b16rf379/dqHS4Lh8PKysq66vNcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJm6xHgDxtWzZMs9rJk2a1KvX+vTTTz2vueeeezyvue+++zyvmT17tuc1knT//fd7XnPs2DHPawoKCjyv6Uv/+9//PK/5/PPPPa/Jz8/3vKY3jh492qt13Iw0sbgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDPSFFNTU9Mna3qrurq6T17njjvu6NW6e++91/OaxsZGz2umTp3qeU1fOn/+vOc1//znPz2v6c0NbbOzsz2vaWlp8bwGiccVEADABAECAJjwHKA9e/bo4YcfVjAYVFpamrZv3x7zvHNOL7zwgvLz8zV48GCVlJToyJEj8ZoXAJAiPAeos7NTkydP1saNG3t8fv369XrllVf02muvad++fbrttts0b968Xn1NGQCQujy/CaGsrExlZWU9Puec04YNG/T8889r/vz5kqTXX39deXl52r59uxYtWnRj0wIAUkZcvwfU2tqqtrY2lZSURB/z+/0qKipSfX19j2u6uroUiURiNgBA6otrgNra2iRJeXl5MY/n5eVFn/u2qqoq+f3+6FZQUBDPkQAA/ZT5u+AqKysVDoej27Fjx6xHAgD0gbgGKBAISJLa29tjHm9vb48+920+n09ZWVkxGwAg9cU1QIWFhQoEAjE/WR+JRLRv3z4VFxfH86UAAEnO87vgzp49q+bm5ujHra2tOnjwoLKzszVixAitXr1av/71r3XXXXepsLBQa9asUTAY1IIFC+I5NwAgyXkO0P79+/XAAw9EP66oqJAkLV68WFu2bNGzzz6rzs5OLV++XGfOnNGMGTNUXV2tQYMGxW9qAEDSS3POOeshvikSicjv91uPAcCj8vJyz2veeecdz2sOHz7sec03/9HsxZdfftmrdbgsHA5f8/v65u+CAwDcnAgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC869jAJD6cnNzPa959dVXPa9JT/f+b+B169Z5XsNdrfsnroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBTAFUKhkOc1w4YN87zmv//9r+c1TU1Nntegf+IKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IgRQ2ffr0Xq37xS9+EedJerZgwQLPaw4fPhz/QWCCKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwVS2EMPPdSrdQMHDvS8pqamxvOa+vp6z2uQOrgCAgCYIEAAABOeA7Rnzx49/PDDCgaDSktL0/bt22OeX7JkidLS0mK20tLSeM0LAEgRngPU2dmpyZMna+PGjVfdp7S0VCdPnoxub7755g0NCQBIPZ7fhFBWVqaysrJr7uPz+RQIBHo9FAAg9SXke0C1tbXKzc3V2LFjtXLlSp0+ffqq+3Z1dSkSicRsAIDUF/cAlZaW6vXXX1dNTY1++9vfqq6uTmVlZbp06VKP+1dVVcnv90e3goKCeI8EAOiH4v5zQIsWLYr+eeLEiZo0aZLGjBmj2tpazZkz54r9KysrVVFREf04EokQIQC4CST8bdijR49WTk6Ompube3ze5/MpKysrZgMApL6EB+j48eM6ffq08vPzE/1SAIAk4vlLcGfPno25mmltbdXBgweVnZ2t7OxsvfTSSyovL1cgEFBLS4ueffZZ3XnnnZo3b15cBwcAJDfPAdq/f78eeOCB6Mdff/9m8eLF2rRpkw4dOqQ//elPOnPmjILBoObOnatf/epX8vl88ZsaAJD00pxzznqIb4pEIvL7/dZjAP3O4MGDPa/Zu3dvr15r/Pjxntc8+OCDntd89NFHntcgeYTD4Wt+X597wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE3H8lN4DEeOaZZzyv+f73v9+r16qurva8hjtbwyuugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFDDwox/9yPOaNWvWeF4TiUQ8r5GkdevW9Wod4AVXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCtygoUOHel7zyiuveF4zYMAAz2v+/Oc/e14jSQ0NDb1aB3jBFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQLf0JsbflZXV3teU1hY6HlNS0uL5zVr1qzxvAboK1wBAQBMECAAgAlPAaqqqtLUqVOVmZmp3NxcLViwQE1NTTH7nD9/XqFQSEOHDtXtt9+u8vJytbe3x3VoAEDy8xSguro6hUIhNTQ06IMPPtDFixc1d+5cdXZ2Rvd56qmn9P777+vdd99VXV2dTpw4oUcffTTugwMAkpunNyF8+5utW7ZsUW5urhobGzVr1iyFw2H98Y9/1NatW/Xggw9KkjZv3qx77rlHDQ0Nuv/+++M3OQAgqd3Q94DC4bAkKTs7W5LU2NioixcvqqSkJLrPuHHjNGLECNXX1/f4Obq6uhSJRGI2AEDq63WAuru7tXr1ak2fPl0TJkyQJLW1tSkjI0NDhgyJ2TcvL09tbW09fp6qqir5/f7oVlBQ0NuRAABJpNcBCoVCOnz4sN56660bGqCyslLhcDi6HTt27IY+HwAgOfTqB1FXrVqlnTt3as+ePRo+fHj08UAgoAsXLujMmTMxV0Ht7e0KBAI9fi6fzyefz9ebMQAASczTFZBzTqtWrdK2bdu0e/fuK36ae8qUKRo4cKBqamqijzU1Neno0aMqLi6Oz8QAgJTg6QooFApp69at2rFjhzIzM6Pf1/H7/Ro8eLD8fr+WLl2qiooKZWdnKysrS08++aSKi4t5BxwAIIanAG3atEmSNHv27JjHN2/erCVLlkiSfv/73ys9PV3l5eXq6urSvHnz9Oqrr8ZlWABA6khzzjnrIb4pEonI7/dbj4Gb1N133+15zWeffZaASa40f/58z2vef//9BEwCfDfhcFhZWVlXfZ57wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEr34jKtDfjRw5slfr/vKXv8R5kp4988wzntfs3LkzAZMAdrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSpKTly5f3at2IESPiPEnP6urqPK9xziVgEsAOV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRop+b8aMGZ7XPPnkkwmYBEA8cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTo92bOnOl5ze23356ASXrW0tLiec3Zs2cTMAmQXLgCAgCYIEAAABOeAlRVVaWpU6cqMzNTubm5WrBggZqammL2mT17ttLS0mK2FStWxHVoAEDy8xSguro6hUIhNTQ06IMPPtDFixc1d+5cdXZ2xuy3bNkynTx5MrqtX78+rkMDAJKfpzchVFdXx3y8ZcsW5ebmqrGxUbNmzYo+fuuttyoQCMRnQgBASrqh7wGFw2FJUnZ2dszjb7zxhnJycjRhwgRVVlbq3LlzV/0cXV1dikQiMRsAIPX1+m3Y3d3dWr16taZPn64JEyZEH3/88cc1cuRIBYNBHTp0SM8995yampr03nvv9fh5qqqq9NJLL/V2DABAkup1gEKhkA4fPqy9e/fGPL58+fLonydOnKj8/HzNmTNHLS0tGjNmzBWfp7KyUhUVFdGPI5GICgoKejsWACBJ9CpAq1at0s6dO7Vnzx4NHz78mvsWFRVJkpqbm3sMkM/nk8/n680YAIAk5ilAzjk9+eST2rZtm2pra1VYWHjdNQcPHpQk5efn92pAAEBq8hSgUCikrVu3aseOHcrMzFRbW5skye/3a/DgwWppadHWrVv10EMPaejQoTp06JCeeuopzZo1S5MmTUrIfwAAIDl5CtCmTZskXf5h02/avHmzlixZooyMDO3atUsbNmxQZ2enCgoKVF5erueffz5uAwMAUoPnL8FdS0FBgerq6m5oIADAzYG7YQPf8Le//c3zmjlz5nhe8+WXX3peA6QabkYKADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhIc9e7xXUfi0Qi8vv91mMAAG5QOBxWVlbWVZ/nCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJfhegfnZrOgBAL13v7/N+F6COjg7rEQAAcXC9v8/73d2wu7u7deLECWVmZiotLS3muUgkooKCAh07duyad1hNdRyHyzgOl3EcLuM4XNYfjoNzTh0dHQoGg0pPv/p1zi19ONN3kp6eruHDh19zn6ysrJv6BPsax+EyjsNlHIfLOA6XWR+H7/Jrdfrdl+AAADcHAgQAMJFUAfL5fFq7dq18Pp/1KKY4DpdxHC7jOFzGcbgsmY5Dv3sTAgDg5pBUV0AAgNRBgAAAJggQAMAEAQIAmEiaAG3cuFGjRo3SoEGDVFRUpI8//th6pD734osvKi0tLWYbN26c9VgJt2fPHj388MMKBoNKS0vT9u3bY553zumFF15Qfn6+Bg8erJKSEh05csRm2AS63nFYsmTJFedHaWmpzbAJUlVVpalTpyozM1O5ublasGCBmpqaYvY5f/68QqGQhg4dqttvv13l5eVqb283mjgxvstxmD179hXnw4oVK4wm7llSBOjtt99WRUWF1q5dq08++USTJ0/WvHnzdOrUKevR+tz48eN18uTJ6LZ3717rkRKus7NTkydP1saNG3t8fv369XrllVf02muvad++fbrttts0b948nT9/vo8nTazrHQdJKi0tjTk/3nzzzT6cMPHq6uoUCoXU0NCgDz74QBcvXtTcuXPV2dkZ3eepp57S+++/r3fffVd1dXU6ceKEHn30UcOp4++7HAdJWrZsWcz5sH79eqOJr8IlgWnTprlQKBT9+NKlSy4YDLqqqirDqfre2rVr3eTJk63HMCXJbdu2Lfpxd3e3CwQC7ne/+130sTNnzjifz+fefPNNgwn7xrePg3POLV682M2fP99kHiunTp1yklxdXZ1z7vL/+4EDB7p33303us+nn37qJLn6+nqrMRPu28fBOed++MMfup/97Gd2Q30H/f4K6MKFC2psbFRJSUn0sfT0dJWUlKi+vt5wMhtHjhxRMBjU6NGj9cQTT+jo0aPWI5lqbW1VW1tbzPnh9/tVVFR0U54ftbW1ys3N1dixY7Vy5UqdPn3aeqSECofDkqTs7GxJUmNjoy5evBhzPowbN04jRoxI6fPh28fha2+88YZycnI0YcIEVVZW6ty5cxbjXVW/uxnpt33xxRe6dOmS8vLyYh7Py8vTZ599ZjSVjaKiIm3ZskVjx47VyZMn9dJLL2nmzJk6fPiwMjMzrccz0dbWJkk9nh9fP3ezKC0t1aOPPqrCwkK1tLTol7/8pcrKylRfX68BAwZYjxd33d3dWr16taZPn64JEyZIunw+ZGRkaMiQITH7pvL50NNxkKTHH39cI0eOVDAY1KFDh/Tcc8+pqalJ7733nuG0sfp9gPD/ysrKon+eNGmSioqKNHLkSL3zzjtaunSp4WToDxYtWhT988SJEzVp0iSNGTNGtbW1mjNnjuFkiREKhXT48OGb4vug13K147B8+fLonydOnKj8/HzNmTNHLS0tGjNmTF+P2aN+/yW4nJwcDRgw4Ip3sbS3tysQCBhN1T8MGTJEd999t5qbm61HMfP1OcD5caXRo0crJycnJc+PVatWaefOnfrwww9jfn1LIBDQhQsXdObMmZj9U/V8uNpx6ElRUZEk9avzod8HKCMjQ1OmTFFNTU30se7ubtXU1Ki4uNhwMntnz55VS0uL8vPzrUcxU1hYqEAgEHN+RCIR7du376Y/P44fP67Tp0+n1PnhnNOqVau0bds27d69W4WFhTHPT5kyRQMHDow5H5qamnT06NGUOh+udxx6cvDgQUnqX+eD9bsgvou33nrL+Xw+t2XLFvePf/zDLV++3A0ZMsS1tbVZj9anfv7zn7va2lrX2trq/vrXv7qSkhKXk5PjTp06ZT1aQnV0dLgDBw64AwcOOEnu5ZdfdgcOHHD/+c9/nHPO/eY3v3FDhgxxO3bscIcOHXLz5893hYWF7quvvjKePL6udRw6Ojrc008/7err611ra6vbtWuXu++++9xdd93lzp8/bz163KxcudL5/X5XW1vrTp48Gd3OnTsX3WfFihVuxIgRbvfu3W7//v2uuLjYFRcXG04df9c7Ds3NzW7dunVu//79rrW11e3YscONHj3azZo1y3jyWEkRIOec+8Mf/uBGjBjhMjIy3LRp01xDQ4P1SH1u4cKFLj8/32VkZLjvfe97buHCha65udl6rIT78MMPnaQrtsWLFzvnLr8Ve82aNS4vL8/5fD43Z84c19TUZDt0AlzrOJw7d87NnTvXDRs2zA0cONCNHDnSLVu2LOX+kdbTf78kt3nz5ug+X331lfvpT3/q7rjjDnfrrbe6Rx55xJ08edJu6AS43nE4evSomzVrlsvOznY+n8/deeed7plnnnHhcNh28G/h1zEAAEz0++8BAQBSEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABg4v8AjVqFRqQZEfIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier output: tensor([[ -6.9609, -17.2949,  -2.1810,  -2.4582, -22.3228,  -5.8204, -26.3086,\n",
      "           6.9209,  -4.2982,  -5.1956]])\n",
      "Classifier prediction: 7\n"
     ]
    }
   ],
   "source": [
    "x, labels = next(test_iter)\n",
    "x = x[0].unsqueeze(0)\n",
    "labels = labels[0].unsqueeze(0)\n",
    "imshow(x[0,0])\n",
    "\n",
    "x = x.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "out = net(x).data\n",
    "print('Classifier output:', out)\n",
    "print('Classifier prediction:', torch.argmax(out).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6nekayzLygn"
   },
   "source": [
    "We can also measure the classifier's accuracy on the full test dataset. This function takes in a classifier we have trained and the loader for the test set, and outputs the classifier's accuracy. The accuracy is simply\n",
    "$$ \\dfrac{\\text{# correct}}{\\text{# total}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lk4pq6hiLygr"
   },
   "outputs": [],
   "source": [
    "def accuracy(net, testloader):\n",
    "    '''\n",
    "    Returns the accuracy of classifier NET\n",
    "    on test data from TESTLOADER.\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "kXpxjHkqLBd8",
    "outputId": "96b7766c-7368-4df9-dc0e-bc1c55b03d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 0])\n",
      "tensor([4, 1, 4, 9])\n",
      "tensor([5, 9, 0, 6])\n",
      "tensor([9, 0, 1, 5])\n",
      "tensor([9, 7, 3, 4])\n",
      "tensor([9, 6, 6, 5])\n",
      "tensor([4, 0, 7, 4])\n",
      "tensor([0, 1, 3, 1])\n",
      "tensor([3, 4, 7, 2])\n",
      "tensor([7, 1, 2, 1])\n",
      "tensor([1, 7, 4, 2])\n",
      "tensor([3, 5, 1, 2])\n",
      "tensor([4, 4, 6, 3])\n",
      "tensor([5, 5, 6, 0])\n",
      "tensor([4, 1, 9, 5])\n",
      "tensor([7, 8, 9, 3])\n",
      "tensor([7, 4, 6, 4])\n",
      "tensor([3, 0, 7, 0])\n",
      "tensor([2, 9, 1, 7])\n",
      "tensor([3, 2, 9, 7])\n",
      "tensor([7, 6, 2, 7])\n",
      "tensor([8, 4, 7, 3])\n",
      "tensor([6, 1, 3, 6])\n",
      "tensor([9, 3, 1, 4])\n",
      "tensor([1, 7, 6, 9])\n",
      "tensor([6, 0, 5, 4])\n",
      "tensor([9, 9, 2, 1])\n",
      "tensor([9, 4, 8, 7])\n",
      "tensor([3, 9, 7, 4])\n",
      "tensor([4, 4, 9, 2])\n",
      "tensor([5, 4, 7, 6])\n",
      "tensor([7, 9, 0, 5])\n",
      "tensor([8, 5, 6, 6])\n",
      "tensor([5, 7, 8, 1])\n",
      "tensor([0, 1, 6, 4])\n",
      "tensor([6, 7, 3, 1])\n",
      "tensor([7, 1, 8, 2])\n",
      "tensor([0, 2, 9, 9])\n",
      "tensor([5, 5, 1, 5])\n",
      "tensor([6, 0, 3, 4])\n",
      "tensor([4, 6, 5, 4])\n",
      "tensor([6, 5, 4, 5])\n",
      "tensor([1, 4, 4, 7])\n",
      "tensor([2, 3, 2, 7])\n",
      "tensor([1, 8, 1, 8])\n",
      "tensor([1, 8, 5, 0])\n",
      "tensor([8, 9, 2, 5])\n",
      "tensor([0, 1, 1, 1])\n",
      "tensor([0, 9, 0, 3])\n",
      "tensor([1, 6, 4, 2])\n",
      "tensor([3, 6, 1, 1])\n",
      "tensor([1, 3, 9, 5])\n",
      "tensor([2, 9, 4, 5])\n",
      "tensor([9, 3, 9, 0])\n",
      "tensor([3, 6, 5, 5])\n",
      "tensor([7, 2, 2, 7])\n",
      "tensor([1, 2, 8, 4])\n",
      "tensor([1, 7, 3, 3])\n",
      "tensor([8, 8, 7, 9])\n",
      "tensor([2, 2, 4, 1])\n",
      "tensor([5, 9, 8, 7])\n",
      "tensor([2, 3, 0, 4])\n",
      "tensor([4, 2, 4, 1])\n",
      "tensor([9, 5, 7, 7])\n",
      "tensor([2, 8, 2, 6])\n",
      "tensor([8, 5, 7, 7])\n",
      "tensor([9, 1, 8, 1])\n",
      "tensor([8, 0, 3, 0])\n",
      "tensor([1, 9, 9, 4])\n",
      "tensor([1, 8, 2, 1])\n",
      "tensor([2, 9, 7, 5])\n",
      "tensor([9, 2, 6, 4])\n",
      "tensor([1, 5, 8, 2])\n",
      "tensor([9, 2, 0, 4])\n",
      "tensor([0, 0, 2, 8])\n",
      "tensor([4, 7, 1, 2])\n",
      "tensor([4, 0, 2, 7])\n",
      "tensor([4, 3, 3, 0])\n",
      "tensor([0, 3, 1, 9])\n",
      "tensor([6, 5, 2, 5])\n",
      "tensor([9, 2, 9, 3])\n",
      "tensor([0, 4, 2, 0])\n",
      "tensor([7, 1, 1, 2])\n",
      "tensor([1, 5, 3, 3])\n",
      "tensor([9, 7, 8, 6])\n",
      "tensor([5, 6, 1, 3])\n",
      "tensor([8, 1, 0, 5])\n",
      "tensor([1, 3, 1, 5])\n",
      "tensor([5, 6, 1, 8])\n",
      "tensor([5, 1, 7, 9])\n",
      "tensor([4, 6, 2, 2])\n",
      "tensor([5, 0, 6, 5])\n",
      "tensor([6, 3, 7, 2])\n",
      "tensor([0, 8, 8, 5])\n",
      "tensor([4, 1, 1, 4])\n",
      "tensor([0, 3, 3, 7])\n",
      "tensor([6, 1, 6, 2])\n",
      "tensor([1, 9, 2, 8])\n",
      "tensor([6, 1, 9, 5])\n",
      "tensor([2, 5, 4, 4])\n",
      "tensor([2, 8, 3, 8])\n",
      "tensor([2, 4, 5, 0])\n",
      "tensor([3, 1, 7, 7])\n",
      "tensor([5, 7, 9, 7])\n",
      "tensor([1, 9, 2, 1])\n",
      "tensor([4, 2, 9, 2])\n",
      "tensor([0, 4, 9, 1])\n",
      "tensor([4, 8, 1, 8])\n",
      "tensor([4, 5, 9, 8])\n",
      "tensor([8, 3, 7, 6])\n",
      "tensor([0, 0, 3, 0])\n",
      "tensor([2, 6, 6, 4])\n",
      "tensor([9, 3, 3, 3])\n",
      "tensor([2, 3, 9, 1])\n",
      "tensor([2, 6, 8, 0])\n",
      "tensor([5, 6, 6, 6])\n",
      "tensor([3, 8, 8, 2])\n",
      "tensor([7, 5, 8, 9])\n",
      "tensor([6, 1, 8, 4])\n",
      "tensor([1, 2, 5, 9])\n",
      "tensor([1, 9, 7, 5])\n",
      "tensor([4, 0, 8, 9])\n",
      "tensor([9, 1, 0, 5])\n",
      "tensor([2, 3, 7, 8])\n",
      "tensor([9, 4, 0, 6])\n",
      "tensor([3, 9, 5, 2])\n",
      "tensor([1, 3, 1, 3])\n",
      "tensor([6, 5, 7, 4])\n",
      "tensor([2, 2, 6, 3])\n",
      "tensor([2, 6, 5, 4])\n",
      "tensor([8, 9, 7, 1])\n",
      "tensor([3, 0, 3, 8])\n",
      "tensor([3, 1, 9, 3])\n",
      "tensor([4, 4, 6, 4])\n",
      "tensor([2, 1, 8, 2])\n",
      "tensor([5, 4, 8, 8])\n",
      "tensor([4, 0, 0, 2])\n",
      "tensor([3, 2, 7, 7])\n",
      "tensor([0, 8, 7, 4])\n",
      "tensor([4, 7, 9, 6])\n",
      "tensor([9, 0, 9, 8])\n",
      "tensor([0, 4, 6, 0])\n",
      "tensor([6, 3, 5, 4])\n",
      "tensor([8, 3, 3, 9])\n",
      "tensor([3, 3, 3, 7])\n",
      "tensor([8, 0, 8, 2])\n",
      "tensor([1, 7, 0, 6])\n",
      "tensor([5, 4, 3, 8])\n",
      "tensor([0, 9, 6, 3])\n",
      "tensor([8, 0, 9, 9])\n",
      "tensor([6, 8, 6, 8])\n",
      "tensor([5, 7, 8, 6])\n",
      "tensor([0, 2, 4, 0])\n",
      "tensor([2, 2, 3, 1])\n",
      "tensor([9, 7, 5, 1])\n",
      "tensor([0, 8, 4, 6])\n",
      "tensor([2, 6, 7, 9])\n",
      "tensor([3, 2, 9, 8])\n",
      "tensor([2, 2, 9, 2])\n",
      "tensor([7, 3, 5, 9])\n",
      "tensor([1, 8, 0, 2])\n",
      "tensor([0, 5, 2, 1])\n",
      "tensor([3, 7, 6, 7])\n",
      "tensor([1, 2, 5, 8])\n",
      "tensor([0, 3, 7, 2])\n",
      "tensor([4, 0, 9, 1])\n",
      "tensor([8, 6, 7, 7])\n",
      "tensor([4, 3, 4, 9])\n",
      "tensor([1, 9, 5, 1])\n",
      "tensor([7, 3, 9, 7])\n",
      "tensor([6, 9, 1, 3])\n",
      "tensor([7, 8, 3, 3])\n",
      "tensor([6, 7, 2, 8])\n",
      "tensor([5, 8, 5, 1])\n",
      "tensor([1, 4, 4, 3])\n",
      "tensor([1, 0, 7, 7])\n",
      "tensor([0, 7, 9, 4])\n",
      "tensor([4, 8, 5, 5])\n",
      "tensor([4, 0, 8, 2])\n",
      "tensor([1, 0, 8, 4])\n",
      "tensor([5, 0, 4, 0])\n",
      "tensor([6, 1, 7, 3])\n",
      "tensor([2, 6, 7, 2])\n",
      "tensor([6, 9, 3, 1])\n",
      "tensor([4, 6, 2, 5])\n",
      "tensor([4, 2, 0, 6])\n",
      "tensor([2, 1, 7, 3])\n",
      "tensor([4, 1, 0, 5])\n",
      "tensor([4, 3, 1, 1])\n",
      "tensor([7, 4, 9, 9])\n",
      "tensor([4, 8, 4, 0])\n",
      "tensor([2, 4, 5, 1])\n",
      "tensor([1, 6, 4, 7])\n",
      "tensor([1, 9, 4, 2])\n",
      "tensor([4, 1, 5, 5])\n",
      "tensor([3, 8, 3, 1])\n",
      "tensor([4, 5, 6, 8])\n",
      "tensor([9, 4, 1, 5])\n",
      "tensor([3, 8, 0, 3])\n",
      "tensor([2, 5, 1, 2])\n",
      "tensor([8, 3, 4, 4])\n",
      "tensor([0, 8, 8, 3])\n",
      "tensor([3, 1, 7, 3])\n",
      "tensor([5, 9, 6, 3])\n",
      "tensor([2, 6, 1, 3])\n",
      "tensor([6, 0, 7, 2])\n",
      "tensor([1, 7, 1, 4])\n",
      "tensor([2, 4, 2, 1])\n",
      "tensor([7, 9, 6, 1])\n",
      "tensor([1, 2, 4, 8])\n",
      "tensor([1, 7, 7, 4])\n",
      "tensor([8, 0, 7, 3])\n",
      "tensor([1, 3, 1, 0])\n",
      "tensor([7, 7, 0, 3])\n",
      "tensor([5, 5, 2, 7])\n",
      "tensor([6, 6, 9, 2])\n",
      "tensor([8, 3, 5, 2])\n",
      "tensor([2, 5, 6, 0])\n",
      "tensor([8, 2, 9, 2])\n",
      "tensor([8, 8, 8, 8])\n",
      "tensor([7, 4, 9, 3])\n",
      "tensor([0, 6, 6, 3])\n",
      "tensor([2, 1, 3, 2])\n",
      "tensor([2, 9, 3, 0])\n",
      "tensor([0, 5, 7, 8])\n",
      "tensor([1, 4, 4, 6])\n",
      "tensor([0, 2, 9, 1])\n",
      "tensor([4, 7, 4, 7])\n",
      "tensor([3, 9, 8, 8])\n",
      "tensor([4, 7, 1, 2])\n",
      "tensor([1, 2, 2, 3])\n",
      "tensor([2, 3, 2, 3])\n",
      "tensor([9, 1, 7, 4])\n",
      "tensor([0, 3, 5, 5])\n",
      "tensor([8, 6, 3, 2])\n",
      "tensor([6, 7, 6, 6])\n",
      "tensor([3, 2, 7, 8])\n",
      "tensor([1, 1, 7, 5])\n",
      "tensor([6, 4, 9, 5])\n",
      "tensor([1, 3, 3, 4])\n",
      "tensor([7, 8, 9, 1])\n",
      "tensor([1, 6, 9, 1])\n",
      "tensor([4, 4, 5, 4])\n",
      "tensor([0, 6, 2, 2])\n",
      "tensor([3, 1, 5, 1])\n",
      "tensor([2, 0, 3, 8])\n",
      "tensor([1, 2, 6, 7])\n",
      "tensor([1, 6, 2, 3])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([2, 0, 8, 9])\n",
      "tensor([9, 0, 2, 5])\n",
      "tensor([1, 9, 7, 8])\n",
      "tensor([1, 0, 4, 1])\n",
      "tensor([7, 9, 6, 4])\n",
      "tensor([2, 6, 8, 1])\n",
      "tensor([3, 7, 5, 4])\n",
      "tensor([4, 1, 8, 1])\n",
      "tensor([3, 8, 1, 2])\n",
      "tensor([5, 8, 0, 6])\n",
      "tensor([2, 1, 1, 7])\n",
      "tensor([1, 5, 3, 4])\n",
      "tensor([6, 9, 5, 0])\n",
      "tensor([9, 2, 2, 4])\n",
      "tensor([8, 2, 1, 7])\n",
      "tensor([2, 4, 9, 4])\n",
      "tensor([4, 0, 3, 9])\n",
      "tensor([2, 2, 3, 3])\n",
      "tensor([8, 3, 5, 7])\n",
      "tensor([3, 5, 8, 1])\n",
      "tensor([2, 4, 4, 6])\n",
      "tensor([4, 9, 5, 1])\n",
      "tensor([0, 6, 9, 5])\n",
      "tensor([9, 5, 9, 7])\n",
      "tensor([3, 8, 0, 3])\n",
      "tensor([7, 1, 3, 6])\n",
      "tensor([7, 8, 5, 9])\n",
      "tensor([7, 9, 6, 9])\n",
      "tensor([6, 3, 7, 4])\n",
      "tensor([4, 5, 3, 5])\n",
      "tensor([4, 7, 8, 7])\n",
      "tensor([8, 0, 7, 6])\n",
      "tensor([8, 8, 7, 3])\n",
      "tensor([3, 1, 9, 5])\n",
      "tensor([2, 7, 3, 5])\n",
      "tensor([1, 1, 2, 1])\n",
      "tensor([4, 7, 4, 7])\n",
      "tensor([5, 4, 5, 4])\n",
      "tensor([0, 8, 3, 6])\n",
      "tensor([9, 6, 0, 2])\n",
      "tensor([7, 4, 4, 4])\n",
      "tensor([4, 6, 6, 4])\n",
      "tensor([7, 9, 3, 4])\n",
      "tensor([5, 5, 8, 7])\n",
      "tensor([3, 7, 2, 7])\n",
      "tensor([0, 2, 4, 1])\n",
      "tensor([1, 6, 6, 9])\n",
      "tensor([2, 8, 7, 2])\n",
      "tensor([0, 1, 5, 0])\n",
      "tensor([9, 1, 7, 0])\n",
      "tensor([6, 0, 8, 6])\n",
      "tensor([8, 1, 8, 0])\n",
      "tensor([3, 3, 7, 2])\n",
      "tensor([3, 6, 2, 1])\n",
      "tensor([6, 1, 1, 3])\n",
      "tensor([7, 9, 0, 8])\n",
      "tensor([0, 5, 4, 0])\n",
      "tensor([2, 8, 7, 2])\n",
      "tensor([9, 8, 4, 0])\n",
      "tensor([9, 5, 8, 5])\n",
      "tensor([1, 2, 1, 3])\n",
      "tensor([1, 7, 4, 5])\n",
      "tensor([7, 2, 0, 9])\n",
      "tensor([8, 8, 6, 2])\n",
      "tensor([5, 4, 1, 9])\n",
      "tensor([2, 1, 5, 8])\n",
      "tensor([7, 0, 2, 4])\n",
      "tensor([4, 3, 6, 8])\n",
      "tensor([8, 2, 4, 0])\n",
      "tensor([5, 0, 4, 4])\n",
      "tensor([7, 9, 3, 4])\n",
      "tensor([1, 5, 9, 7])\n",
      "tensor([3, 5, 8, 8])\n",
      "tensor([0, 5, 3, 3])\n",
      "tensor([6, 6, 0, 1])\n",
      "tensor([6, 0, 3, 5])\n",
      "tensor([4, 4, 1, 2])\n",
      "tensor([9, 1, 4, 6])\n",
      "tensor([9, 9, 3, 9])\n",
      "tensor([8, 4, 4, 3])\n",
      "tensor([1, 3, 1, 8])\n",
      "tensor([8, 7, 9, 4])\n",
      "tensor([8, 8, 7, 9])\n",
      "tensor([7, 1, 4, 5])\n",
      "tensor([6, 0, 5, 2])\n",
      "tensor([2, 2, 1, 5])\n",
      "tensor([5, 2, 4, 9])\n",
      "tensor([6, 2, 7, 7])\n",
      "tensor([2, 2, 1, 1])\n",
      "tensor([2, 8, 3, 7])\n",
      "tensor([2, 4, 1, 7])\n",
      "tensor([1, 7, 6, 7])\n",
      "tensor([8, 2, 7, 3])\n",
      "tensor([1, 7, 5, 8])\n",
      "tensor([2, 6, 2, 2])\n",
      "tensor([5, 6, 5, 0])\n",
      "tensor([9, 2, 4, 3])\n",
      "tensor([3, 9, 7, 6])\n",
      "tensor([6, 8, 0, 4])\n",
      "tensor([1, 5, 8, 2])\n",
      "tensor([9, 1, 8, 0])\n",
      "tensor([6, 7, 2, 1])\n",
      "tensor([0, 5, 5, 2])\n",
      "tensor([0, 2, 2, 0])\n",
      "tensor([2, 4, 9, 8])\n",
      "tensor([0, 9, 9, 4])\n",
      "tensor([6, 5, 4, 9])\n",
      "tensor([1, 8, 3, 4])\n",
      "tensor([9, 9, 1, 2])\n",
      "tensor([2, 8, 1, 9])\n",
      "tensor([6, 4, 0, 9])\n",
      "tensor([4, 8, 3, 8])\n",
      "tensor([6, 0, 2, 5])\n",
      "tensor([1, 9, 6, 2])\n",
      "tensor([9, 4, 0, 9])\n",
      "tensor([6, 0, 6, 2])\n",
      "tensor([5, 4, 2, 3])\n",
      "tensor([8, 4, 5, 5])\n",
      "tensor([0, 3, 8, 5])\n",
      "tensor([3, 5, 8, 6])\n",
      "tensor([5, 7, 6, 3])\n",
      "tensor([3, 9, 6, 1])\n",
      "tensor([1, 2, 9, 0])\n",
      "tensor([4, 3, 3, 6])\n",
      "tensor([9, 5, 7, 3])\n",
      "tensor([7, 7, 7, 8])\n",
      "tensor([7, 9, 8, 3])\n",
      "tensor([0, 7, 2, 7])\n",
      "tensor([9, 4, 5, 4])\n",
      "tensor([9, 3, 2, 1])\n",
      "tensor([4, 0, 2, 3])\n",
      "tensor([7, 5, 7, 8])\n",
      "tensor([8, 5, 0, 1])\n",
      "tensor([1, 4, 8, 3])\n",
      "tensor([9, 0, 0, 0])\n",
      "tensor([6, 6, 2, 3])\n",
      "tensor([7, 8, 4, 7])\n",
      "tensor([7, 9, 2, 4])\n",
      "tensor([1, 4, 5, 2])\n",
      "tensor([4, 9, 9, 1])\n",
      "tensor([8, 4, 0, 9])\n",
      "tensor([8, 4, 8, 7])\n",
      "tensor([7, 0, 7, 8])\n",
      "tensor([8, 6, 0, 4])\n",
      "tensor([8, 8, 2, 4])\n",
      "tensor([7, 6, 6, 6])\n",
      "tensor([4, 7, 1, 8])\n",
      "tensor([8, 2, 3, 6])\n",
      "tensor([3, 0, 0, 3])\n",
      "tensor([7, 6, 9, 7])\n",
      "tensor([9, 9, 5, 4])\n",
      "tensor([3, 3, 6, 1])\n",
      "tensor([2, 3, 7, 3])\n",
      "tensor([3, 2, 0, 3])\n",
      "tensor([3, 8, 4, 3])\n",
      "tensor([6, 3, 5, 0])\n",
      "tensor([2, 0, 9, 0])\n",
      "tensor([7, 4, 6, 9])\n",
      "tensor([3, 5, 1, 9])\n",
      "tensor([6, 1, 4, 5])\n",
      "tensor([4, 5, 0, 5])\n",
      "tensor([9, 5, 2, 1])\n",
      "tensor([2, 9, 1, 9])\n",
      "tensor([9, 4, 0, 8])\n",
      "tensor([4, 5, 2, 9])\n",
      "tensor([2, 1, 2, 1])\n",
      "tensor([7, 3, 6, 8])\n",
      "tensor([8, 4, 9, 1])\n",
      "tensor([9, 8, 5, 7])\n",
      "tensor([5, 1, 1, 8])\n",
      "tensor([6, 5, 2, 4])\n",
      "tensor([4, 3, 2, 3])\n",
      "tensor([5, 6, 8, 8])\n",
      "tensor([6, 2, 3, 1])\n",
      "tensor([0, 5, 8, 9])\n",
      "tensor([2, 9, 6, 7])\n",
      "tensor([0, 4, 8, 7])\n",
      "tensor([1, 7, 4, 1])\n",
      "tensor([0, 9, 7, 2])\n",
      "tensor([0, 0, 9, 1])\n",
      "tensor([7, 8, 7, 8])\n",
      "tensor([4, 7, 2, 0])\n",
      "tensor([4, 6, 0, 3])\n",
      "tensor([1, 1, 3, 3])\n",
      "tensor([9, 6, 7, 4])\n",
      "tensor([1, 5, 3, 0])\n",
      "tensor([8, 7, 3, 9])\n",
      "tensor([6, 9, 3, 5])\n",
      "tensor([0, 2, 7, 4])\n",
      "tensor([5, 1, 7, 5])\n",
      "tensor([8, 0, 8, 8])\n",
      "tensor([1, 5, 0, 3])\n",
      "tensor([0, 3, 1, 4])\n",
      "tensor([0, 3, 7, 2])\n",
      "tensor([7, 1, 8, 0])\n",
      "tensor([7, 0, 4, 3])\n",
      "tensor([1, 9, 8, 7])\n",
      "tensor([7, 1, 4, 9])\n",
      "tensor([9, 3, 2, 1])\n",
      "tensor([7, 9, 0, 2])\n",
      "tensor([0, 3, 3, 7])\n",
      "tensor([6, 9, 2, 3])\n",
      "tensor([3, 7, 7, 0])\n",
      "tensor([0, 7, 5, 2])\n",
      "tensor([9, 8, 7, 4])\n",
      "tensor([4, 2, 6, 6])\n",
      "tensor([1, 9, 6, 8])\n",
      "tensor([2, 9, 0, 8])\n",
      "tensor([3, 1, 1, 6])\n",
      "tensor([3, 5, 1, 1])\n",
      "tensor([1, 3, 1, 2])\n",
      "tensor([3, 0, 2, 0])\n",
      "tensor([1, 3, 5, 5])\n",
      "tensor([7, 4, 8, 9])\n",
      "tensor([6, 9, 6, 8])\n",
      "tensor([3, 6, 6, 8])\n",
      "tensor([5, 1, 4, 2])\n",
      "tensor([4, 4, 5, 1])\n",
      "tensor([1, 9, 0, 2])\n",
      "tensor([4, 9, 5, 7])\n",
      "tensor([1, 8, 8, 5])\n",
      "tensor([6, 9, 8, 7])\n",
      "tensor([1, 1, 6, 7])\n",
      "tensor([6, 3, 2, 2])\n",
      "tensor([0, 8, 9, 2])\n",
      "tensor([5, 1, 0, 8])\n",
      "tensor([1, 9, 5, 7])\n",
      "tensor([9, 6, 9, 0])\n",
      "tensor([6, 1, 5, 5])\n",
      "tensor([8, 3, 8, 2])\n",
      "tensor([6, 5, 0, 7])\n",
      "tensor([4, 6, 1, 3])\n",
      "tensor([4, 7, 3, 2])\n",
      "tensor([3, 4, 2, 5])\n",
      "tensor([2, 7, 1, 7])\n",
      "tensor([2, 6, 4, 1])\n",
      "tensor([5, 7, 8, 6])\n",
      "tensor([0, 1, 8, 2])\n",
      "tensor([5, 7, 7, 6])\n",
      "tensor([9, 3, 5, 8])\n",
      "tensor([4, 2, 4, 0])\n",
      "tensor([8, 8, 3, 4])\n",
      "tensor([9, 2, 7, 5])\n",
      "tensor([8, 6, 5, 6])\n",
      "tensor([0, 8, 6, 7])\n",
      "tensor([3, 6, 4, 9])\n",
      "tensor([4, 6, 6, 3])\n",
      "tensor([2, 4, 1, 0])\n",
      "tensor([1, 4, 6, 2])\n",
      "tensor([9, 1, 1, 0])\n",
      "tensor([6, 3, 9, 5])\n",
      "tensor([6, 5, 6, 5])\n",
      "tensor([8, 4, 6, 4])\n",
      "tensor([3, 9, 1, 3])\n",
      "tensor([4, 1, 9, 1])\n",
      "tensor([7, 1, 1, 9])\n",
      "tensor([3, 5, 4, 0])\n",
      "tensor([7, 3, 6, 1])\n",
      "tensor([7, 5, 5, 3])\n",
      "tensor([3, 0, 1, 5])\n",
      "tensor([7, 5, 8, 6])\n",
      "tensor([5, 1, 0, 4])\n",
      "tensor([2, 3, 4, 6])\n",
      "tensor([7, 9, 8, 1])\n",
      "tensor([8, 4, 9, 2])\n",
      "tensor([8, 6, 2, 7])\n",
      "tensor([0, 0, 6, 7])\n",
      "tensor([5, 8, 6, 0])\n",
      "tensor([9, 3, 7, 1])\n",
      "tensor([3, 5, 4, 3])\n",
      "tensor([3, 5, 5, 6])\n",
      "tensor([3, 0, 2, 3])\n",
      "tensor([4, 2, 3, 0])\n",
      "tensor([9, 9, 4, 7])\n",
      "tensor([2, 8, 4, 7])\n",
      "tensor([0, 6, 2, 8])\n",
      "tensor([5, 2, 8, 5])\n",
      "tensor([7, 3, 0, 8])\n",
      "tensor([2, 3, 2, 8])\n",
      "tensor([2, 5, 5, 7])\n",
      "tensor([6, 4, 6, 8])\n",
      "tensor([4, 8, 2, 7])\n",
      "tensor([4, 5, 2, 0])\n",
      "tensor([3, 9, 4, 6])\n",
      "tensor([7, 2, 5, 6])\n",
      "tensor([1, 1, 2, 3])\n",
      "tensor([6, 7, 8, 7])\n",
      "tensor([6, 4, 8, 9])\n",
      "tensor([4, 8, 6, 3])\n",
      "tensor([8, 3, 1, 0])\n",
      "tensor([6, 2, 2, 5])\n",
      "tensor([6, 9, 5, 8])\n",
      "tensor([1, 4, 1, 7])\n",
      "tensor([8, 4, 6, 1])\n",
      "tensor([8, 4, 3, 1])\n",
      "tensor([2, 8, 0, 8])\n",
      "tensor([5, 9, 1, 4])\n",
      "tensor([2, 0, 2, 7])\n",
      "tensor([0, 9, 0, 2])\n",
      "tensor([5, 7, 6, 7])\n",
      "tensor([9, 4, 2, 6])\n",
      "tensor([2, 4, 4, 8])\n",
      "tensor([0, 4, 4, 5])\n",
      "tensor([8, 0, 6, 8])\n",
      "tensor([9, 8, 5, 6])\n",
      "tensor([9, 0, 4, 8])\n",
      "tensor([7, 1, 3, 4])\n",
      "tensor([5, 8, 0, 9])\n",
      "tensor([1, 3, 3, 6])\n",
      "tensor([9, 8, 7, 1])\n",
      "tensor([0, 5, 7, 1])\n",
      "tensor([7, 5, 2, 7])\n",
      "tensor([9, 1, 8, 5])\n",
      "tensor([2, 4, 9, 4])\n",
      "tensor([7, 2, 2, 3])\n",
      "tensor([4, 9, 1, 9])\n",
      "tensor([2, 1, 7, 9])\n",
      "tensor([4, 4, 1, 6])\n",
      "tensor([7, 2, 7, 8])\n",
      "tensor([8, 1, 9, 7])\n",
      "tensor([1, 1, 7, 5])\n",
      "tensor([3, 3, 5, 1])\n",
      "tensor([3, 7, 6, 1])\n",
      "tensor([3, 8, 7, 5])\n",
      "tensor([9, 9, 0, 0])\n",
      "tensor([2, 8, 8, 2])\n",
      "tensor([3, 7, 1, 3])\n",
      "tensor([0, 3, 4, 4])\n",
      "tensor([3, 8, 9, 2])\n",
      "tensor([3, 9, 7, 1])\n",
      "tensor([1, 7, 0, 4])\n",
      "tensor([9, 6, 5, 9])\n",
      "tensor([1, 7, 0, 2])\n",
      "tensor([0, 0, 4, 6])\n",
      "tensor([7, 0, 7, 1])\n",
      "tensor([4, 6, 4, 5])\n",
      "tensor([4, 9, 9, 1])\n",
      "tensor([7, 9, 5, 3])\n",
      "tensor([3, 8, 2, 3])\n",
      "tensor([6, 2, 2, 1])\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([6, 9, 8, 4])\n",
      "tensor([3, 7, 1, 6])\n",
      "tensor([4, 5, 0, 4])\n",
      "tensor([7, 4, 2, 4])\n",
      "tensor([0, 7, 0, 1])\n",
      "tensor([9, 8, 8, 6])\n",
      "tensor([0, 0, 4, 9])\n",
      "tensor([6, 8, 2, 2])\n",
      "tensor([3, 8, 4, 8])\n",
      "tensor([2, 2, 1, 7])\n",
      "tensor([5, 4, 4, 0])\n",
      "tensor([4, 3, 9, 7])\n",
      "tensor([3, 1, 0, 1])\n",
      "tensor([2, 5, 9, 2])\n",
      "tensor([1, 0, 1, 8])\n",
      "tensor([9, 1, 6, 8])\n",
      "tensor([3, 8, 9, 3])\n",
      "tensor([6, 2, 8, 3])\n",
      "tensor([2, 2, 1, 0])\n",
      "tensor([4, 2, 9, 2])\n",
      "tensor([4, 3, 7, 9])\n",
      "tensor([1, 5, 2, 4])\n",
      "tensor([9, 0, 3, 8])\n",
      "tensor([5, 3, 6, 0])\n",
      "tensor([9, 4, 6, 2])\n",
      "tensor([5, 0, 2, 7])\n",
      "tensor([4, 6, 6, 8])\n",
      "tensor([6, 6, 8, 6])\n",
      "tensor([9, 1, 7, 2])\n",
      "tensor([5, 9, 9, 0])\n",
      "tensor([7, 2, 7, 6])\n",
      "tensor([7, 0, 6, 5])\n",
      "tensor([2, 4, 7, 2])\n",
      "tensor([0, 9, 9, 2])\n",
      "tensor([2, 9, 4, 4])\n",
      "tensor([2, 3, 3, 2])\n",
      "tensor([1, 7, 0, 7])\n",
      "tensor([6, 4, 1, 3])\n",
      "tensor([8, 7, 4, 5])\n",
      "tensor([9, 2, 5, 1])\n",
      "tensor([8, 7, 3, 7])\n",
      "tensor([1, 5, 5, 0])\n",
      "tensor([9, 1, 4, 0])\n",
      "tensor([6, 3, 3, 6])\n",
      "tensor([0, 4, 9, 7])\n",
      "tensor([5, 1, 6, 8])\n",
      "tensor([9, 5, 5, 7])\n",
      "tensor([9, 3, 8, 3])\n",
      "tensor([8, 1, 5, 3])\n",
      "tensor([5, 0, 5, 5])\n",
      "tensor([3, 8, 6, 7])\n",
      "tensor([7, 7, 3, 7])\n",
      "tensor([0, 5, 9, 0])\n",
      "tensor([2, 5, 5, 3])\n",
      "tensor([1, 7, 7, 8])\n",
      "tensor([6, 5, 9, 3])\n",
      "tensor([8, 9, 5, 3])\n",
      "tensor([7, 9, 1, 7])\n",
      "tensor([0, 0, 3, 7])\n",
      "tensor([2, 5, 8, 1])\n",
      "tensor([8, 6, 2, 9])\n",
      "tensor([5, 7, 5, 7])\n",
      "tensor([8, 6, 2, 5])\n",
      "tensor([1, 4, 8, 4])\n",
      "tensor([5, 8, 3, 0])\n",
      "tensor([6, 2, 7, 3])\n",
      "tensor([3, 2, 1, 0])\n",
      "tensor([7, 3, 4, 0])\n",
      "tensor([3, 9, 3, 2])\n",
      "tensor([8, 9, 0, 3])\n",
      "tensor([8, 0, 7, 6])\n",
      "tensor([5, 4, 7, 3])\n",
      "tensor([9, 0, 8, 6])\n",
      "tensor([2, 5, 6, 1])\n",
      "tensor([0, 0, 4, 4])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([2, 7, 7, 8])\n",
      "tensor([5, 2, 5, 7])\n",
      "tensor([6, 9, 1, 4])\n",
      "tensor([1, 6, 4, 2])\n",
      "tensor([4, 3, 5, 4])\n",
      "tensor([3, 9, 5, 0])\n",
      "tensor([1, 5, 3, 8])\n",
      "tensor([9, 1, 9, 7])\n",
      "tensor([9, 5, 5, 2])\n",
      "tensor([7, 4, 6, 0])\n",
      "tensor([1, 1, 1, 0])\n",
      "tensor([4, 4, 7, 6])\n",
      "tensor([3, 0, 0, 4])\n",
      "tensor([3, 0, 6, 1])\n",
      "tensor([9, 6, 1, 3])\n",
      "tensor([8, 1, 2, 5])\n",
      "tensor([6, 2, 7, 3])\n",
      "tensor([6, 0, 1, 9])\n",
      "tensor([7, 6, 6, 8])\n",
      "tensor([9, 2, 9, 5])\n",
      "tensor([8, 3, 1, 0])\n",
      "tensor([0, 7, 6, 6])\n",
      "tensor([2, 1, 6, 9])\n",
      "tensor([3, 1, 8, 6])\n",
      "tensor([9, 0, 6, 0])\n",
      "tensor([0, 0, 6, 3])\n",
      "tensor([5, 9, 3, 4])\n",
      "tensor([5, 5, 8, 5])\n",
      "tensor([3, 0, 4, 0])\n",
      "tensor([2, 9, 6, 8])\n",
      "tensor([2, 3, 1, 2])\n",
      "tensor([1, 1, 5, 6])\n",
      "tensor([9, 8, 0, 6])\n",
      "tensor([6, 5, 5, 3])\n",
      "tensor([8, 6, 2, 1])\n",
      "tensor([4, 5, 4, 3])\n",
      "tensor([7, 8, 5, 0])\n",
      "tensor([9, 3, 5, 1])\n",
      "tensor([1, 0, 4, 4])\n",
      "tensor([7, 0, 1, 7])\n",
      "tensor([0, 1, 6, 1])\n",
      "tensor([4, 5, 6, 6])\n",
      "tensor([5, 7, 8, 4])\n",
      "tensor([4, 7, 2, 5])\n",
      "tensor([3, 7, 0, 7])\n",
      "tensor([7, 9, 6, 4])\n",
      "tensor([2, 8, 5, 7])\n",
      "tensor([8, 3, 9, 5])\n",
      "tensor([8, 9, 9, 8])\n",
      "tensor([6, 2, 8, 9])\n",
      "tensor([2, 3, 6, 1])\n",
      "tensor([1, 8, 9, 3])\n",
      "tensor([4, 0, 7, 9])\n",
      "tensor([6, 4, 1, 4])\n",
      "tensor([1, 3, 4, 9])\n",
      "tensor([3, 1, 4, 7])\n",
      "tensor([7, 4, 7, 2])\n",
      "tensor([9, 3, 0, 8])\n",
      "tensor([8, 8, 4, 0])\n",
      "tensor([4, 4, 1, 5])\n",
      "tensor([2, 8, 3, 4])\n",
      "tensor([9, 5, 2, 8])\n",
      "tensor([1, 5, 3, 7])\n",
      "tensor([9, 4, 2, 5])\n",
      "tensor([6, 3, 5, 9])\n",
      "tensor([3, 5, 9, 3])\n",
      "tensor([1, 9, 5, 3])\n",
      "tensor([0, 6, 9, 8])\n",
      "tensor([4, 0, 4, 9])\n",
      "tensor([2, 9, 0, 1])\n",
      "tensor([0, 3, 1, 6])\n",
      "tensor([5, 8, 1, 5])\n",
      "tensor([3, 3, 0, 3])\n",
      "tensor([5, 5, 9, 2])\n",
      "tensor([8, 7, 0, 4])\n",
      "tensor([9, 1, 9, 7])\n",
      "tensor([7, 5, 5, 2])\n",
      "tensor([0, 9, 1, 8])\n",
      "tensor([6, 2, 3, 9])\n",
      "tensor([6, 2, 1, 9])\n",
      "tensor([1, 3, 5, 5])\n",
      "tensor([0, 3, 8, 3])\n",
      "tensor([3, 7, 6, 6])\n",
      "tensor([0, 1, 4, 0])\n",
      "tensor([6, 9, 8, 1])\n",
      "tensor([2, 9, 9, 5])\n",
      "tensor([9, 7, 3, 7])\n",
      "tensor([8, 0, 1, 3])\n",
      "tensor([0, 4, 6, 1])\n",
      "tensor([0, 2, 5, 8])\n",
      "tensor([4, 4, 1, 1])\n",
      "tensor([5, 4, 6, 6])\n",
      "tensor([0, 6, 9, 2])\n",
      "tensor([6, 2, 7, 1])\n",
      "tensor([7, 9, 4, 0])\n",
      "tensor([0, 3, 8, 2])\n",
      "tensor([2, 3, 1, 6])\n",
      "tensor([0, 5, 7, 7])\n",
      "tensor([9, 2, 6, 7])\n",
      "tensor([9, 7, 8, 6])\n",
      "tensor([8, 8, 4, 6])\n",
      "tensor([8, 4, 1, 2])\n",
      "tensor([8, 1, 3, 9])\n",
      "tensor([4, 0, 3, 7])\n",
      "tensor([3, 2, 3, 3])\n",
      "tensor([7, 3, 4, 0])\n",
      "tensor([6, 2, 0, 8])\n",
      "tensor([1, 5, 3, 5])\n",
      "tensor([4, 1, 7, 1])\n",
      "tensor([5, 7, 5, 7])\n",
      "tensor([3, 2, 2, 7])\n",
      "tensor([3, 7, 3, 7])\n",
      "tensor([8, 5, 4, 5])\n",
      "tensor([2, 5, 6, 5])\n",
      "tensor([3, 6, 7, 4])\n",
      "tensor([1, 7, 1, 5])\n",
      "tensor([2, 3, 6, 3])\n",
      "tensor([1, 4, 2, 6])\n",
      "tensor([7, 4, 3, 8])\n",
      "tensor([0, 6, 2, 1])\n",
      "tensor([6, 5, 3, 9])\n",
      "tensor([1, 9, 3, 2])\n",
      "tensor([1, 8, 4, 4])\n",
      "tensor([6, 5, 8, 6])\n",
      "tensor([9, 7, 7, 8])\n",
      "tensor([6, 9, 7, 3])\n",
      "tensor([9, 4, 0, 5])\n",
      "tensor([4, 6, 4, 1])\n",
      "tensor([2, 3, 0, 0])\n",
      "tensor([2, 6, 6, 5])\n",
      "tensor([7, 0, 8, 6])\n",
      "tensor([4, 7, 9, 0])\n",
      "tensor([7, 3, 4, 2])\n",
      "tensor([1, 8, 8, 5])\n",
      "tensor([9, 2, 7, 1])\n",
      "tensor([8, 8, 8, 2])\n",
      "tensor([7, 6, 0, 1])\n",
      "tensor([2, 7, 1, 0])\n",
      "tensor([8, 3, 6, 0])\n",
      "tensor([5, 3, 6, 2])\n",
      "tensor([8, 7, 0, 1])\n",
      "tensor([4, 2, 1, 1])\n",
      "tensor([4, 4, 4, 4])\n",
      "tensor([7, 1, 6, 2])\n",
      "tensor([9, 9, 0, 0])\n",
      "tensor([1, 8, 8, 4])\n",
      "tensor([3, 4, 2, 0])\n",
      "tensor([6, 1, 6, 1])\n",
      "tensor([2, 2, 2, 1])\n",
      "tensor([2, 3, 7, 8])\n",
      "tensor([1, 0, 0, 2])\n",
      "tensor([1, 6, 6, 0])\n",
      "tensor([1, 6, 2, 5])\n",
      "tensor([1, 7, 4, 8])\n",
      "tensor([2, 1, 4, 3])\n",
      "tensor([8, 3, 9, 9])\n",
      "tensor([4, 8, 3, 4])\n",
      "tensor([7, 2, 7, 5])\n",
      "tensor([7, 0, 4, 3])\n",
      "tensor([3, 2, 6, 7])\n",
      "tensor([6, 0, 0, 6])\n",
      "tensor([7, 7, 0, 5])\n",
      "tensor([5, 8, 1, 0])\n",
      "tensor([7, 0, 2, 8])\n",
      "tensor([1, 5, 0, 8])\n",
      "tensor([8, 0, 3, 2])\n",
      "tensor([7, 7, 2, 6])\n",
      "tensor([4, 7, 5, 5])\n",
      "tensor([5, 2, 9, 2])\n",
      "tensor([8, 4, 6, 8])\n",
      "tensor([6, 5, 0, 0])\n",
      "tensor([8, 7, 6, 1])\n",
      "tensor([7, 1, 1, 2])\n",
      "tensor([7, 4, 0, 0])\n",
      "tensor([7, 7, 6, 3])\n",
      "tensor([8, 6, 4, 2])\n",
      "tensor([0, 9, 4, 0])\n",
      "tensor([5, 7, 8, 2])\n",
      "tensor([7, 4, 7, 1])\n",
      "tensor([1, 3, 6, 6])\n",
      "tensor([2, 9, 1, 9])\n",
      "tensor([4, 8, 3, 6])\n",
      "tensor([9, 5, 9, 6])\n",
      "tensor([2, 4, 6, 7])\n",
      "tensor([7, 0, 6, 6])\n",
      "tensor([9, 4, 8, 3])\n",
      "tensor([5, 3, 4, 9])\n",
      "tensor([0, 0, 5, 2])\n",
      "tensor([5, 0, 7, 1])\n",
      "tensor([1, 1, 6, 7])\n",
      "tensor([6, 7, 9, 6])\n",
      "tensor([6, 4, 1, 4])\n",
      "tensor([3, 1, 1, 2])\n",
      "tensor([2, 4, 1, 0])\n",
      "tensor([8, 7, 6, 3])\n",
      "tensor([4, 0, 0, 6])\n",
      "tensor([3, 3, 0, 7])\n",
      "tensor([1, 7, 1, 1])\n",
      "tensor([3, 1, 0, 9])\n",
      "tensor([9, 7, 5, 4])\n",
      "tensor([1, 4, 8, 9])\n",
      "tensor([5, 3, 5, 1])\n",
      "tensor([9, 8, 2, 3])\n",
      "tensor([3, 9, 9, 0])\n",
      "tensor([1, 0, 2, 9])\n",
      "tensor([3, 9, 3, 3])\n",
      "tensor([6, 2, 4, 9])\n",
      "tensor([8, 3, 7, 4])\n",
      "tensor([0, 4, 7, 8])\n",
      "tensor([4, 9, 8, 9])\n",
      "tensor([9, 7, 5, 9])\n",
      "tensor([2, 8, 2, 2])\n",
      "tensor([0, 2, 2, 3])\n",
      "tensor([8, 4, 6, 8])\n",
      "tensor([6, 8, 2, 4])\n",
      "tensor([6, 7, 9, 3])\n",
      "tensor([3, 9, 4, 3])\n",
      "tensor([1, 4, 4, 7])\n",
      "tensor([0, 5, 9, 6])\n",
      "tensor([0, 4, 4, 4])\n",
      "tensor([4, 6, 1, 2])\n",
      "tensor([3, 3, 6, 4])\n",
      "tensor([5, 9, 6, 8])\n",
      "tensor([5, 6, 5, 8])\n",
      "tensor([6, 4, 1, 8])\n",
      "tensor([6, 5, 2, 8])\n",
      "tensor([4, 5, 5, 4])\n",
      "tensor([7, 7, 0, 7])\n",
      "tensor([8, 2, 2, 3])\n",
      "tensor([7, 0, 1, 8])\n",
      "tensor([0, 7, 1, 9])\n",
      "tensor([8, 7, 5, 5])\n",
      "tensor([9, 1, 7, 5])\n",
      "tensor([4, 9, 1, 2])\n",
      "tensor([2, 1, 6, 6])\n",
      "tensor([7, 1, 1, 4])\n",
      "tensor([0, 7, 4, 2])\n",
      "tensor([4, 0, 6, 4])\n",
      "tensor([7, 6, 9, 5])\n",
      "tensor([3, 4, 6, 5])\n",
      "tensor([0, 1, 8, 8])\n",
      "tensor([2, 8, 3, 5])\n",
      "tensor([7, 8, 0, 8])\n",
      "tensor([5, 7, 1, 1])\n",
      "tensor([0, 1, 3, 7])\n",
      "tensor([8, 5, 0, 7])\n",
      "tensor([1, 1, 0, 1])\n",
      "tensor([1, 4, 5, 2])\n",
      "tensor([7, 6, 2, 3])\n",
      "tensor([0, 2, 8, 5])\n",
      "tensor([9, 6, 9, 7])\n",
      "tensor([2, 1, 3, 6])\n",
      "tensor([4, 1, 8, 2])\n",
      "tensor([4, 0, 5, 1])\n",
      "tensor([0, 2, 2, 6])\n",
      "tensor([4, 4, 3, 9])\n",
      "tensor([6, 1, 6, 5])\n",
      "tensor([7, 9, 2, 0])\n",
      "tensor([2, 6, 0, 1])\n",
      "tensor([4, 3, 5, 2])\n",
      "tensor([8, 8, 0, 8])\n",
      "tensor([8, 9, 0, 9])\n",
      "tensor([6, 7, 6, 3])\n",
      "tensor([9, 3, 4, 7])\n",
      "tensor([7, 7, 4, 9])\n",
      "tensor([0, 6, 4, 8])\n",
      "tensor([4, 2, 7, 2])\n",
      "tensor([8, 1, 0, 0])\n",
      "tensor([7, 8, 3, 3])\n",
      "tensor([3, 1, 3, 7])\n",
      "tensor([6, 1, 3, 1])\n",
      "tensor([6, 6, 5, 7])\n",
      "tensor([4, 7, 5, 9])\n",
      "tensor([5, 8, 4, 9])\n",
      "tensor([9, 1, 6, 5])\n",
      "tensor([0, 1, 3, 7])\n",
      "tensor([0, 3, 4, 8])\n",
      "tensor([2, 2, 0, 2])\n",
      "tensor([5, 1, 5, 1])\n",
      "tensor([4, 8, 8, 9])\n",
      "tensor([1, 2, 1, 3])\n",
      "tensor([5, 1, 0, 9])\n",
      "tensor([4, 4, 8, 3])\n",
      "tensor([2, 5, 9, 7])\n",
      "tensor([6, 6, 2, 0])\n",
      "tensor([0, 0, 5, 8])\n",
      "tensor([7, 1, 5, 2])\n",
      "tensor([3, 8, 5, 1])\n",
      "tensor([8, 2, 0, 4])\n",
      "tensor([9, 9, 6, 2])\n",
      "tensor([3, 3, 5, 6])\n",
      "tensor([4, 8, 0, 9])\n",
      "tensor([2, 8, 3, 6])\n",
      "tensor([7, 5, 7, 2])\n",
      "tensor([9, 4, 9, 1])\n",
      "tensor([2, 8, 6, 0])\n",
      "tensor([7, 0, 9, 1])\n",
      "tensor([1, 6, 7, 5])\n",
      "tensor([9, 9, 1, 9])\n",
      "tensor([5, 9, 2, 5])\n",
      "tensor([0, 4, 1, 0])\n",
      "tensor([8, 9, 0, 8])\n",
      "tensor([9, 8, 9, 4])\n",
      "tensor([2, 5, 7, 9])\n",
      "tensor([8, 9, 8, 0])\n",
      "tensor([9, 9, 6, 8])\n",
      "tensor([9, 9, 5, 9])\n",
      "tensor([8, 5, 1, 0])\n",
      "tensor([3, 3, 5, 2])\n",
      "tensor([1, 6, 5, 0])\n",
      "tensor([2, 8, 1, 5])\n",
      "tensor([6, 2, 3, 0])\n",
      "tensor([2, 2, 6, 4])\n",
      "tensor([3, 5, 5, 1])\n",
      "tensor([7, 2, 1, 6])\n",
      "tensor([9, 1, 9, 9])\n",
      "tensor([5, 5, 1, 6])\n",
      "tensor([2, 2, 8, 6])\n",
      "tensor([7, 1, 4, 6])\n",
      "tensor([0, 4, 0, 3])\n",
      "tensor([3, 2, 2, 3])\n",
      "tensor([6, 8, 9, 8])\n",
      "tensor([5, 3, 8, 5])\n",
      "tensor([4, 5, 2, 0])\n",
      "tensor([5, 6, 3, 2])\n",
      "tensor([8, 3, 9, 9])\n",
      "tensor([5, 7, 9, 4])\n",
      "tensor([6, 7, 1, 3])\n",
      "tensor([7, 3, 6, 6])\n",
      "tensor([0, 9, 0, 1])\n",
      "tensor([9, 9, 2, 8])\n",
      "tensor([8, 0, 1, 6])\n",
      "tensor([9, 7, 5, 3])\n",
      "tensor([4, 7, 4, 9])\n",
      "tensor([9, 4, 3, 6])\n",
      "tensor([3, 1, 1, 7])\n",
      "tensor([6, 9, 1, 8])\n",
      "tensor([4, 1, 1, 9])\n",
      "tensor([9, 4, 3, 6])\n",
      "tensor([8, 1, 6, 0])\n",
      "tensor([4, 1, 3, 7])\n",
      "tensor([7, 4, 9, 5])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([1, 6, 2, 1])\n",
      "tensor([9, 8, 4, 0])\n",
      "tensor([3, 6, 4, 9])\n",
      "tensor([0, 7, 1, 6])\n",
      "tensor([5, 7, 5, 2])\n",
      "tensor([5, 1, 8, 5])\n",
      "tensor([4, 7, 0, 6])\n",
      "tensor([7, 0, 2, 5])\n",
      "tensor([8, 1, 0, 4])\n",
      "tensor([5, 7, 1, 8])\n",
      "tensor([5, 1, 9, 0])\n",
      "tensor([0, 6, 0, 7])\n",
      "tensor([3, 1, 8, 3])\n",
      "tensor([9, 7, 0, 0])\n",
      "tensor([8, 9, 5, 9])\n",
      "tensor([8, 3, 2, 7])\n",
      "tensor([2, 9, 7, 2])\n",
      "tensor([1, 1, 3, 7])\n",
      "tensor([5, 3, 1, 9])\n",
      "tensor([8, 2, 2, 2])\n",
      "tensor([8, 8, 5, 7])\n",
      "tensor([3, 8, 9, 8])\n",
      "tensor([8, 6, 8, 2])\n",
      "tensor([3, 9, 7, 5])\n",
      "tensor([6, 2, 9, 2])\n",
      "tensor([8, 8, 1, 6])\n",
      "tensor([8, 8, 7, 9])\n",
      "tensor([1, 8, 0, 1])\n",
      "tensor([7, 2, 0, 7])\n",
      "tensor([5, 1, 9, 0])\n",
      "tensor([2, 0, 9, 8])\n",
      "tensor([6, 2, 3, 9])\n",
      "tensor([3, 8, 0, 2])\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([4, 2, 9, 7])\n",
      "tensor([2, 5, 1, 1])\n",
      "tensor([2, 1, 9, 9])\n",
      "tensor([9, 1, 0, 2])\n",
      "tensor([0, 2, 1, 1])\n",
      "tensor([4, 6, 4, 1])\n",
      "tensor([5, 4, 9, 7])\n",
      "tensor([7, 1, 5, 6])\n",
      "tensor([2, 2, 2, 8])\n",
      "tensor([0, 6, 9, 6])\n",
      "tensor([1, 9, 7, 7])\n",
      "tensor([1, 4, 8, 5])\n",
      "tensor([3, 4, 3, 4])\n",
      "tensor([9, 7, 5, 0])\n",
      "tensor([7, 4, 8, 8])\n",
      "tensor([1, 5, 3, 9])\n",
      "tensor([5, 9, 7, 6])\n",
      "tensor([9, 0, 3, 6])\n",
      "tensor([3, 9, 8, 2])\n",
      "tensor([2, 1, 2, 8])\n",
      "tensor([6, 8, 5, 5])\n",
      "tensor([3, 9, 4, 9])\n",
      "tensor([2, 5, 1, 5])\n",
      "tensor([1, 4, 4, 1])\n",
      "tensor([4, 4, 3, 5])\n",
      "tensor([9, 1, 2, 2])\n",
      "tensor([3, 3, 0, 2])\n",
      "tensor([9, 0, 0, 9])\n",
      "tensor([9, 6, 0, 9])\n",
      "tensor([3, 2, 8, 4])\n",
      "tensor([1, 9, 9, 7])\n",
      "tensor([2, 7, 9, 9])\n",
      "tensor([5, 9, 5, 1])\n",
      "tensor([1, 8, 3, 5])\n",
      "tensor([1, 9, 5, 3])\n",
      "tensor([5, 4, 9, 5])\n",
      "tensor([9, 3, 1, 9])\n",
      "tensor([0, 9, 7, 5])\n",
      "tensor([4, 9, 2, 0])\n",
      "tensor([1, 0, 5, 1])\n",
      "tensor([4, 9, 3, 3])\n",
      "tensor([6, 1, 5, 2])\n",
      "tensor([5, 2, 2, 0])\n",
      "tensor([9, 2, 6, 6])\n",
      "tensor([0, 1, 2, 0])\n",
      "tensor([3, 0, 2, 5])\n",
      "tensor([5, 7, 9, 5])\n",
      "tensor([5, 0, 8, 9])\n",
      "tensor([5, 0, 3, 2])\n",
      "tensor([5, 9, 0, 8])\n",
      "tensor([8, 4, 5, 8])\n",
      "tensor([8, 4, 5, 4])\n",
      "tensor([8, 5, 4, 9])\n",
      "tensor([2, 2, 1, 2])\n",
      "tensor([6, 8, 8, 7])\n",
      "tensor([0, 3, 6, 6])\n",
      "tensor([4, 3, 8, 8])\n",
      "tensor([7, 2, 2, 0])\n",
      "tensor([0, 9, 3, 9])\n",
      "tensor([9, 1, 9, 8])\n",
      "tensor([6, 6, 4, 2])\n",
      "tensor([6, 9, 2, 8])\n",
      "tensor([5, 4, 5, 7])\n",
      "tensor([9, 9, 9, 2])\n",
      "tensor([1, 8, 3, 4])\n",
      "tensor([0, 7, 8, 3])\n",
      "tensor([9, 3, 4, 6])\n",
      "tensor([5, 6, 2, 3])\n",
      "tensor([9, 2, 6, 0])\n",
      "tensor([0, 6, 1, 2])\n",
      "tensor([8, 7, 9, 8])\n",
      "tensor([2, 0, 4, 7])\n",
      "tensor([7, 5, 0, 5])\n",
      "tensor([6, 4, 6, 7])\n",
      "tensor([4, 3, 0, 7])\n",
      "tensor([5, 0, 7, 4])\n",
      "tensor([2, 0, 8, 9])\n",
      "tensor([9, 4, 2, 4])\n",
      "tensor([6, 7, 8, 7])\n",
      "tensor([6, 9, 4, 1])\n",
      "tensor([3, 7, 3, 0])\n",
      "tensor([8, 8, 7, 6])\n",
      "tensor([9, 3, 9, 2])\n",
      "tensor([2, 9, 2, 1])\n",
      "tensor([8, 3, 2, 9])\n",
      "tensor([6, 8, 4, 0])\n",
      "tensor([1, 2, 8, 4])\n",
      "tensor([5, 2, 7, 8])\n",
      "tensor([1, 1, 3, 0])\n",
      "tensor([3, 5, 7, 0])\n",
      "tensor([3, 1, 9, 3])\n",
      "tensor([6, 3, 1, 7])\n",
      "tensor([7, 3, 0, 8])\n",
      "tensor([4, 8, 2, 6])\n",
      "tensor([5, 2, 9, 7])\n",
      "tensor([3, 9, 0, 9])\n",
      "tensor([9, 6, 4, 2])\n",
      "tensor([9, 7, 2, 1])\n",
      "tensor([1, 6, 7, 4])\n",
      "tensor([7, 5, 9, 6])\n",
      "tensor([8, 2, 1, 4])\n",
      "tensor([4, 5, 7, 6])\n",
      "tensor([1, 3, 2, 5])\n",
      "tensor([9, 9, 3, 6])\n",
      "tensor([1, 1, 4, 6])\n",
      "tensor([9, 7, 2, 1])\n",
      "tensor([5, 1, 4, 6])\n",
      "tensor([3, 8, 1, 1])\n",
      "tensor([0, 3, 1, 6])\n",
      "tensor([8, 4, 9, 0])\n",
      "tensor([7, 3, 0, 2])\n",
      "tensor([9, 0, 6, 6])\n",
      "tensor([6, 3, 6, 7])\n",
      "tensor([7, 2, 8, 6])\n",
      "tensor([0, 8, 3, 0])\n",
      "tensor([2, 9, 8, 3])\n",
      "tensor([2, 5, 3, 8])\n",
      "tensor([8, 0, 0, 1])\n",
      "tensor([9, 5, 1, 3])\n",
      "tensor([9, 6, 0, 1])\n",
      "tensor([4, 1, 7, 1])\n",
      "tensor([2, 3, 7, 9])\n",
      "tensor([7, 4, 9, 9])\n",
      "tensor([3, 9, 2, 8])\n",
      "tensor([2, 7, 1, 8])\n",
      "tensor([0, 9, 1, 0])\n",
      "tensor([1, 7, 7, 9])\n",
      "tensor([6, 9, 9, 9])\n",
      "tensor([2, 1, 6, 1])\n",
      "tensor([3, 5, 7, 1])\n",
      "tensor([9, 7, 6, 4])\n",
      "tensor([5, 7, 6, 6])\n",
      "tensor([9, 9, 6, 3])\n",
      "tensor([6, 2, 9, 8])\n",
      "tensor([1, 2, 2, 5])\n",
      "tensor([5, 2, 3, 7])\n",
      "tensor([2, 1, 0, 1])\n",
      "tensor([0, 4, 5, 2])\n",
      "tensor([8, 2, 8, 3])\n",
      "tensor([5, 1, 7, 8])\n",
      "tensor([1, 1, 2, 9])\n",
      "tensor([7, 8, 4, 0])\n",
      "tensor([3, 0, 7, 8])\n",
      "tensor([8, 4, 7, 7])\n",
      "tensor([8, 5, 8, 4])\n",
      "tensor([9, 8, 1, 3])\n",
      "tensor([8, 0, 3, 1])\n",
      "tensor([7, 9, 5, 5])\n",
      "tensor([1, 6, 5, 7])\n",
      "tensor([4, 9, 3, 5])\n",
      "tensor([4, 7, 1, 2])\n",
      "tensor([0, 8, 1, 6])\n",
      "tensor([0, 7, 3, 4])\n",
      "tensor([7, 3, 9, 6])\n",
      "tensor([0, 8, 6, 4])\n",
      "tensor([8, 7, 7, 9])\n",
      "tensor([3, 8, 6, 9])\n",
      "tensor([7, 2, 3, 4])\n",
      "tensor([0, 2, 1, 8])\n",
      "tensor([3, 5, 5, 7])\n",
      "tensor([2, 4, 6, 7])\n",
      "tensor([2, 8, 3, 0])\n",
      "tensor([8, 7, 8, 9])\n",
      "tensor([0, 8, 4, 4])\n",
      "tensor([5, 8, 5, 6])\n",
      "tensor([6, 3, 0, 9])\n",
      "tensor([3, 7, 6, 8])\n",
      "tensor([9, 3, 4, 9])\n",
      "tensor([5, 8, 9, 1])\n",
      "tensor([2, 8, 8, 6])\n",
      "tensor([8, 1, 3, 7])\n",
      "tensor([9, 0, 1, 1])\n",
      "tensor([4, 7, 0, 8])\n",
      "tensor([1, 7, 4, 5])\n",
      "tensor([7, 1, 2, 1])\n",
      "tensor([1, 3, 9, 6])\n",
      "tensor([2, 1, 2, 8])\n",
      "tensor([0, 7, 6, 6])\n",
      "tensor([9, 3, 7, 0])\n",
      "tensor([5, 2, 8, 0])\n",
      "tensor([5, 4, 3, 8])\n",
      "tensor([4, 6, 6, 2])\n",
      "tensor([7, 9, 5, 1])\n",
      "tensor([3, 2, 4, 3])\n",
      "tensor([6, 1, 9, 4])\n",
      "tensor([4, 7, 6, 5])\n",
      "tensor([4, 1, 9, 9])\n",
      "tensor([2, 7, 8, 0])\n",
      "tensor([1, 3, 6, 1])\n",
      "tensor([3, 4, 1, 1])\n",
      "tensor([1, 5, 6, 0])\n",
      "tensor([7, 0, 7, 2])\n",
      "tensor([3, 2, 5, 2])\n",
      "tensor([2, 9, 4, 9])\n",
      "tensor([8, 1, 2, 1])\n",
      "tensor([6, 1, 2, 7])\n",
      "tensor([8, 0, 0, 0])\n",
      "tensor([8, 2, 2, 9])\n",
      "tensor([2, 2, 7, 9])\n",
      "tensor([9, 2, 7, 5])\n",
      "tensor([1, 3, 4, 9])\n",
      "tensor([4, 1, 8, 5])\n",
      "tensor([6, 2, 8, 3])\n",
      "tensor([1, 2, 8, 4])\n",
      "tensor([9, 9, 3, 7])\n",
      "tensor([0, 7, 7, 2])\n",
      "tensor([3, 2, 4, 0])\n",
      "tensor([3, 9, 9, 8])\n",
      "tensor([4, 1, 0, 6])\n",
      "tensor([0, 9, 6, 8])\n",
      "tensor([6, 1, 1, 9])\n",
      "tensor([8, 9, 2, 3])\n",
      "tensor([5, 5, 9, 4])\n",
      "tensor([2, 1, 9, 4])\n",
      "tensor([3, 9, 6, 0])\n",
      "tensor([4, 0, 6, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 8, 3, 4])\n",
      "tensor([7, 8, 6, 3])\n",
      "tensor([4, 0, 9, 7])\n",
      "tensor([1, 9, 3, 8])\n",
      "tensor([4, 7, 3, 0])\n",
      "tensor([9, 1, 4, 5])\n",
      "tensor([4, 6, 2, 0])\n",
      "tensor([6, 2, 1, 1])\n",
      "tensor([1, 1, 7, 2])\n",
      "tensor([4, 7, 5, 2])\n",
      "tensor([9, 4, 5, 8])\n",
      "tensor([4, 2, 9, 7])\n",
      "tensor([0, 0, 7, 5])\n",
      "tensor([1, 1, 7, 6])\n",
      "tensor([6, 6, 8, 2])\n",
      "tensor([2, 7, 7, 4])\n",
      "tensor([0, 2, 4, 2])\n",
      "tensor([1, 8, 9, 6])\n",
      "tensor([1, 0, 5, 9])\n",
      "tensor([6, 9, 8, 0])\n",
      "tensor([3, 0, 8, 3])\n",
      "tensor([9, 6, 3, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 5, 4])\n",
      "tensor([8, 7, 4, 7])\n",
      "tensor([7, 3, 9, 8])\n",
      "tensor([8, 3, 1, 5])\n",
      "tensor([8, 2, 7, 4])\n",
      "tensor([2, 1, 5, 4])\n",
      "tensor([5, 5, 8, 6])\n",
      "tensor([4, 4, 4, 1])\n",
      "tensor([8, 7, 5, 5])\n",
      "tensor([1, 8, 9, 1])\n",
      "tensor([3, 6, 3, 3])\n",
      "tensor([2, 2, 6, 9])\n",
      "tensor([9, 6, 5, 5])\n",
      "tensor([3, 3, 8, 1])\n",
      "tensor([6, 5, 6, 8])\n",
      "tensor([1, 9, 7, 6])\n",
      "tensor([8, 3, 7, 4])\n",
      "tensor([7, 0, 9, 0])\n",
      "tensor([0, 3, 7, 9])\n",
      "tensor([3, 0, 2, 0])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([4, 0, 1, 0])\n",
      "tensor([4, 7, 9, 6])\n",
      "tensor([2, 6, 2, 2])\n",
      "tensor([9, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([8, 0, 5, 6])\n",
      "tensor([6, 0, 8, 0])\n",
      "tensor([2, 3, 7, 9])\n",
      "tensor([4, 7, 1, 9])\n",
      "tensor([1, 7, 1, 4])\n",
      "tensor([0, 0, 4, 1])\n",
      "tensor([7, 5, 7, 1])\n",
      "tensor([3, 3, 3, 1])\n",
      "tensor([6, 9, 7, 4])\n",
      "tensor([3, 0, 2, 5])\n",
      "tensor([2, 6, 0, 8])\n",
      "tensor([9, 4, 3, 5])\n",
      "tensor([4, 8, 1, 5])\n",
      "tensor([9, 0, 6, 4])\n",
      "tensor([3, 6, 3, 3])\n",
      "tensor([8, 1, 4, 7])\n",
      "tensor([5, 7, 2, 2])\n",
      "tensor([0, 0, 1, 7])\n",
      "tensor([7, 9, 5, 9])\n",
      "tensor([8, 9, 6, 8])\n",
      "tensor([8, 2, 3, 6])\n",
      "tensor([1, 2, 9, 8])\n",
      "tensor([9, 5, 2, 6])\n",
      "tensor([2, 4, 8, 4])\n",
      "tensor([6, 5, 0, 1])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 7, 4, 2])\n",
      "tensor([0, 9, 0, 1])\n",
      "tensor([5, 8, 8, 0])\n",
      "tensor([2, 7, 8, 4])\n",
      "tensor([4, 6, 1, 0])\n",
      "tensor([4, 5, 3, 9])\n",
      "tensor([4, 2, 0, 5])\n",
      "tensor([0, 1, 3, 2])\n",
      "tensor([9, 1, 6, 0])\n",
      "tensor([1, 1, 8, 0])\n",
      "tensor([4, 7, 7, 6])\n",
      "tensor([3, 6, 0, 7])\n",
      "tensor([3, 5, 4, 2])\n",
      "tensor([4, 1, 8, 3])\n",
      "tensor([5, 6, 7, 0])\n",
      "tensor([6, 7, 1, 2])\n",
      "tensor([5, 8, 1, 9])\n",
      "tensor([3, 8, 2, 8])\n",
      "tensor([7, 6, 7, 1])\n",
      "tensor([4, 6, 2, 9])\n",
      "tensor([3, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 0, 1, 2])\n",
      "tensor([3, 4, 5, 0])\n",
      "tensor([1, 2, 8, 9])\n",
      "tensor([1, 4, 0, 9])\n",
      "tensor([5, 0, 8, 0])\n",
      "tensor([7, 7, 1, 1])\n",
      "tensor([2, 9, 3, 6])\n",
      "tensor([7, 2, 3, 8])\n",
      "tensor([1, 2, 9, 8])\n",
      "tensor([8, 7, 1, 7])\n",
      "tensor([1, 1, 0, 3])\n",
      "tensor([4, 2, 6, 4])\n",
      "tensor([7, 4, 2, 7])\n",
      "tensor([4, 9, 1, 0])\n",
      "tensor([6, 8, 5, 5])\n",
      "tensor([5, 3, 5, 9])\n",
      "tensor([7, 4, 8, 5])\n",
      "tensor([9, 6, 9, 3])\n",
      "tensor([0, 3, 8, 9])\n",
      "tensor([1, 8, 1, 6])\n",
      "tensor([0, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 3])\n",
      "tensor([5, 3, 2, 9])\n",
      "tensor([3, 2, 1, 4])\n",
      "tensor([5, 5, 2, 3])\n",
      "tensor([2, 1, 3, 9])\n",
      "tensor([7, 2, 1, 2])\n",
      "tensor([8, 9, 1, 8])\n",
      "tensor([8, 7, 8, 1])\n",
      "tensor([0, 0, 7, 7])\n",
      "tensor([8, 7, 5, 0])\n",
      "tensor([6, 1, 5, 7])\n",
      "tensor([4, 6, 1, 2])\n",
      "tensor([5, 0, 7, 9])\n",
      "tensor([9, 0, 3, 8])\n",
      "tensor([4, 4, 8, 1])\n",
      "tensor([8, 6, 5, 9])\n",
      "tensor([0, 0, 0, 3])\n",
      "tensor([7, 1, 6, 4])\n",
      "tensor([2, 6, 6, 0])\n",
      "tensor([4, 5, 4, 1])\n",
      "tensor([3, 8, 6, 3])\n",
      "tensor([9, 9, 5, 9])\n",
      "tensor([3, 7, 8, 5])\n",
      "tensor([6, 4, 7, 6])\n",
      "tensor([2, 2, 0, 9])\n",
      "tensor([4, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 5])\n",
      "tensor([6, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([8, 7, 1, 3])\n",
      "tensor([2, 8, 0, 7])\n",
      "tensor([5, 9, 9, 6])\n",
      "tensor([0, 9, 4, 1])\n",
      "tensor([3, 2, 1, 2])\n",
      "tensor([3, 8, 3, 2])\n",
      "tensor([6, 5, 6, 8])\n",
      "tensor([2, 7, 4, 8])\n",
      "tensor([1, 8, 0, 5])\n",
      "tensor([3, 9, 4, 1])\n",
      "tensor([9, 2, 1, 9])\n",
      "tensor([6, 7, 9, 0])\n",
      "tensor([4, 6, 1, 7])\n",
      "tensor([3, 8, 7, 2])\n",
      "tensor([9, 6, 5, 8])\n",
      "tensor([3, 9, 0, 5])\n",
      "tensor([7, 1, 6, 1])\n",
      "tensor([0, 9, 3, 3])\n",
      "tensor([4, 4, 0, 6])\n",
      "tensor([2, 5, 4, 2])\n",
      "tensor([3, 4, 6, 0])\n",
      "tensor([0, 2, 0, 1])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 8, 7, 1])\n",
      "tensor([3, 7, 5, 2])\n",
      "tensor([8, 0, 7, 5])\n",
      "tensor([9, 9, 0, 9])\n",
      "tensor([1, 1, 5, 8])\n",
      "tensor([8, 6, 3, 2])\n",
      "tensor([1, 8, 3, 2])\n",
      "tensor([6, 5, 6, 7])\n",
      "tensor([4, 1, 0, 5])\n",
      "tensor([3, 1, 9, 2])\n",
      "tensor([1, 9, 6, 0])\n",
      "tensor([4, 6, 1, 7])\n",
      "tensor([3, 8, 7, 2])\n",
      "tensor([9, 6, 5, 8])\n",
      "tensor([3, 5, 7, 1])\n",
      "tensor([6, 1, 0, 9])\n",
      "tensor([6, 2, 5, 4])\n",
      "tensor([2, 3, 4, 4])\n",
      "tensor([6, 0, 0, 2])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 8, 6])\n",
      "tensor([5, 0, 6, 8])\n",
      "tensor([9, 4, 1, 9])\n",
      "tensor([5, 3, 0, 4])\n",
      "tensor([8, 9, 1, 4])\n",
      "tensor([0, 5, 5, 2])\n",
      "tensor([1, 5, 4, 0])\n",
      "tensor([7, 6, 0, 1])\n",
      "tensor([7, 0, 6, 8])\n",
      "tensor([9, 5, 1, 7])\n",
      "tensor([9, 8, 6, 0])\n",
      "tensor([8, 1, 7, 7])\n",
      "tensor([1, 3, 2, 3])\n",
      "tensor([1, 4, 2, 0])\n",
      "tensor([0, 7, 8, 4])\n",
      "tensor([6, 4, 9, 3])\n",
      "tensor([8, 4, 7, 2])\n",
      "tensor([5, 6, 3, 6])\n",
      "tensor([9, 6, 3, 2])\n",
      "tensor([2, 4, 6, 9])\n",
      "tensor([0, 2, 5, 5])\n",
      "tensor([1, 3, 3, 9])\n",
      "tensor([7, 8, 7, 2])\n",
      "tensor([2, 5, 7, 9])\n",
      "tensor([8, 2, 1, 3])\n",
      "tensor([1, 3, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([1, 2, 6, 5])\n",
      "tensor([3, 0, 7, 0])\n",
      "tensor([4, 1, 4, 3])\n",
      "tensor([6, 7, 2, 3])\n",
      "tensor([1, 2, 1, 2])\n",
      "tensor([9, 6, 0, 1])\n",
      "tensor([3, 0, 2, 7])\n",
      "tensor([5, 7, 6, 2])\n",
      "tensor([9, 1, 9, 0])\n",
      "tensor([6, 0, 6, 0])\n",
      "tensor([2, 0, 6, 1])\n",
      "tensor([5, 8, 4, 3])\n",
      "tensor([0, 1, 5, 4])\n",
      "tensor([4, 8, 5, 7])\n",
      "tensor([5, 7, 8, 3])\n",
      "tensor([4, 8, 8, 5])\n",
      "tensor([2, 9, 7, 1])\n",
      "tensor([3, 8, 1, 0])\n",
      "tensor([7, 5, 9, 6])\n",
      "tensor([9, 4, 7, 7])\n",
      "tensor([9, 9, 3, 4])\n",
      "tensor([4, 3, 8, 6])\n",
      "tensor([2, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([8, 3, 9, 5])\n",
      "tensor([5, 2, 6, 8])\n",
      "tensor([4, 9, 1, 7])\n",
      "tensor([1, 2, 3, 5])\n",
      "tensor([9, 6, 9, 1])\n",
      "tensor([1, 1, 2, 9])\n",
      "tensor([5, 6, 8, 1])\n",
      "tensor([2, 0, 7, 7])\n",
      "tensor([5, 8, 2, 9])\n",
      "tensor([8, 9, 0, 4])\n",
      "tensor([6, 7, 1, 3])\n",
      "tensor([4, 5, 6, 0])\n",
      "tensor([3, 6, 8, 7])\n",
      "tensor([0, 4, 2, 7])\n",
      "tensor([4, 7, 5, 4])\n",
      "tensor([3, 4, 2, 8])\n",
      "tensor([1, 5, 1, 2])\n",
      "tensor([0, 2, 5, 6])\n",
      "tensor([4, 3, 0, 0])\n",
      "tensor([0, 3, 3, 5])\n",
      "tensor([7, 0, 6, 4])\n",
      "tensor([8, 8, 6, 3])\n",
      "tensor([4, 6, 9, 9])\n",
      "tensor([8, 2, 7, 7])\n",
      "tensor([1, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 2, 1, 7])\n",
      "tensor([2, 5, 0, 8])\n",
      "tensor([0, 2, 7, 8])\n",
      "tensor([8, 3, 6, 0])\n",
      "tensor([2, 7, 6, 6])\n",
      "tensor([1, 2, 8, 8])\n",
      "tensor([7, 7, 4, 7])\n",
      "tensor([7, 3, 7, 4])\n",
      "tensor([5, 4, 3, 3])\n",
      "tensor([8, 4, 1, 1])\n",
      "tensor([9, 7, 4, 3])\n",
      "tensor([7, 3, 3, 0])\n",
      "tensor([2, 5, 5, 6])\n",
      "tensor([6, 3, 5, 2])\n",
      "tensor([5, 9, 9, 8])\n",
      "tensor([4, 1, 0, 6])\n",
      "tensor([0, 9, 6, 8])\n",
      "tensor([8, 5, 6, 1])\n",
      "tensor([1, 9, 8, 9])\n",
      "tensor([2, 3, 5, 5])\n",
      "tensor([9, 4, 2, 1])\n",
      "tensor([9, 3, 9, 2])\n",
      "tensor([0, 6, 0, 4])\n",
      "tensor([0, 0, 1, 2])\n",
      "tensor([3, 4, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 7, 8, 9])\n",
      "tensor([7, 3, 0, 3])\n",
      "tensor([1, 8, 7, 6])\n",
      "tensor([4, 0, 2, 6])\n",
      "tensor([8, 3, 2, 8])\n",
      "tensor([1, 2, 0, 7])\n",
      "tensor([1, 0, 4, 4])\n",
      "tensor([5, 8, 0, 6])\n",
      "tensor([2, 3, 1, 5])\n",
      "tensor([1, 8, 5, 9])\n",
      "tensor([4, 0, 7, 5])\n",
      "tensor([8, 8, 3, 8])\n",
      "tensor([9, 2, 6, 2])\n",
      "tensor([5, 3, 1, 7])\n",
      "tensor([3, 9, 1, 9])\n",
      "tensor([9, 6, 0, 3])\n",
      "tensor([9, 2, 8, 1])\n",
      "tensor([4, 3, 5, 2])\n",
      "tensor([9, 2, 5, 8])\n",
      "tensor([9, 5, 0, 1])\n",
      "tensor([2, 4, 5, 6])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 1, 0, 4])\n",
      "tensor([5, 6, 6, 3])\n",
      "tensor([4, 4, 2, 8])\n",
      "tensor([1, 0, 6, 4])\n",
      "tensor([9, 7, 2, 3])\n",
      "tensor([3, 9, 2, 0])\n",
      "tensor([9, 3, 3, 9])\n",
      "tensor([1, 5, 2, 3])\n",
      "tensor([7, 7, 8, 4])\n",
      "tensor([0, 2, 4, 0])\n",
      "tensor([2, 4, 7, 8])\n",
      "tensor([0, 7, 0, 6])\n",
      "tensor([9, 3, 2, 8])\n",
      "tensor([6, 0, 5, 7])\n",
      "tensor([5, 1, 0, 8])\n",
      "tensor([1, 6, 7, 2])\n",
      "tensor([9, 7, 9, 5])\n",
      "tensor([8, 6, 2, 6])\n",
      "tensor([2, 8, 1, 7])\n",
      "tensor([5, 0, 1, 1])\n",
      "tensor([3, 8, 4, 9])\n",
      "tensor([1, 8, 6, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 7, 8, 9])\n",
      "tensor([9, 8, 9, 8])\n",
      "tensor([4, 1, 7, 7])\n",
      "tensor([3, 3, 7, 6])\n",
      "tensor([6, 6, 1, 9])\n",
      "tensor([0, 1, 7, 6])\n",
      "tensor([3, 2, 1, 7])\n",
      "tensor([1, 3, 9, 1])\n",
      "tensor([7, 6, 8, 4])\n",
      "tensor([1, 4, 3, 6])\n",
      "tensor([9, 6, 1, 4])\n",
      "tensor([4, 7, 2, 4])\n",
      "tensor([4, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 8, 1, 3])\n",
      "tensor([5, 1, 7, 7])\n",
      "tensor([2, 1, 4, 8])\n",
      "tensor([3, 4, 4, 3])\n",
      "tensor([9, 7, 4, 1])\n",
      "tensor([2, 3, 5, 9])\n",
      "tensor([1, 6, 0, 1])\n",
      "tensor([0, 0, 2, 8])\n",
      "tensor([7, 1, 1, 4])\n",
      "tensor([0, 4, 7, 3])\n",
      "tensor([6, 8, 0, 3])\n",
      "tensor([7, 4, 0, 6])\n",
      "tensor([9, 2, 6, 5])\n",
      "tensor([8, 6, 9, 0])\n",
      "tensor([4, 0, 6, 1])\n",
      "tensor([9, 2, 0, 9])\n",
      "tensor([5, 1, 3, 7])\n",
      "tensor([6, 9, 3, 0])\n",
      "tensor([2, 2, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([2, 1, 7, 2])\n",
      "tensor([5, 0, 8, 0])\n",
      "tensor([2, 7, 8, 8])\n",
      "tensor([3, 0, 6, 0])\n",
      "tensor([2, 7, 6, 6])\n",
      "tensor([1, 2, 8, 8])\n",
      "tensor([7, 7, 4, 7])\n",
      "tensor([7, 3, 7, 4])\n",
      "tensor([5, 4, 3, 3])\n",
      "tensor([8, 4, 5, 4])\n",
      "tensor([1, 1, 9, 7])\n",
      "tensor([4, 3, 7, 3])\n",
      "tensor([3, 0, 2, 5])\n",
      "tensor([5, 6, 3, 1])\n",
      "tensor([5, 2, 5, 9])\n",
      "tensor([9, 8, 4, 1])\n",
      "tensor([0, 6, 0, 9])\n",
      "tensor([6, 8, 8, 5])\n",
      "tensor([6, 1, 1, 9])\n",
      "tensor([8, 9, 2, 3])\n",
      "tensor([5, 5, 9, 4])\n",
      "tensor([2, 1, 9, 4])\n",
      "tensor([9, 1, 3, 9])\n",
      "tensor([2, 0, 6, 0])\n",
      "tensor([4, 0, 6, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 3, 8, 0])\n",
      "tensor([7, 1, 0, 7])\n",
      "tensor([5, 5, 6, 9])\n",
      "tensor([0, 1, 0, 0])\n",
      "tensor([8, 3, 4, 3])\n",
      "tensor([1, 5, 0, 0])\n",
      "tensor([9, 5, 3, 4])\n",
      "tensor([9, 3, 7, 6])\n",
      "tensor([9, 2, 4, 5])\n",
      "tensor([7, 2, 6, 4])\n",
      "tensor([9, 4, 9, 4])\n",
      "tensor([1, 2, 2, 5])\n",
      "tensor([8, 1, 3, 2])\n",
      "tensor([9, 4, 3, 8])\n",
      "tensor([2, 2, 1, 2])\n",
      "tensor([8, 6, 5, 1])\n",
      "tensor([6, 7, 2, 1])\n",
      "tensor([3, 9, 3, 8])\n",
      "tensor([7, 5, 7, 0])\n",
      "tensor([7, 4, 8, 8])\n",
      "tensor([5, 0, 6, 6])\n",
      "tensor([3, 7, 6, 9])\n",
      "tensor([9, 4, 8, 4])\n",
      "tensor([1, 0, 6, 6])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 7, 4])\n",
      "tensor([0, 4, 0, 1])\n",
      "tensor([7, 9, 5, 1])\n",
      "tensor([4, 2, 8, 9])\n",
      "tensor([4, 3, 7, 8])\n",
      "tensor([2, 4, 4, 3])\n",
      "tensor([3, 6, 9, 9])\n",
      "tensor([5, 8, 6, 7])\n",
      "tensor([0, 6, 8, 2])\n",
      "tensor([6, 3, 9, 3])\n",
      "tensor([2, 8, 6, 1])\n",
      "tensor([7, 4, 8, 8])\n",
      "tensor([9, 0, 3, 3])\n",
      "tensor([9, 0, 5, 2])\n",
      "tensor([9, 4, 1, 0])\n",
      "tensor([3, 7, 5, 8])\n",
      "tensor([7, 7, 8, 2])\n",
      "tensor([9, 7, 1, 2])\n",
      "tensor([6, 4, 2, 5])\n",
      "tensor([2, 3, 6, 6])\n",
      "tensor([5, 0, 0, 2])\n",
      "tensor([8, 1, 6, 1])\n",
      "tensor([0, 4, 3, 1])\n",
      "tensor([6, 1, 9, 0])\n",
      "tensor([1, 4, 5, 6])\n",
      "tensor([7, 8, 9, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([8, 4, 0, 0])\n",
      "tensor([7, 2, 4, 3])\n",
      "tensor([8, 6, 6, 3])\n",
      "tensor([2, 6, 3, 3])\n",
      "tensor([0, 1, 4, 7])\n",
      "tensor([8, 0, 3, 1])\n",
      "tensor([9, 0, 1, 9])\n",
      "tensor([1, 2, 7, 0])\n",
      "tensor([1, 3, 8, 2])\n",
      "tensor([9, 2, 7, 6])\n",
      "tensor([5, 5, 9, 9])\n",
      "tensor([8, 2, 9, 1])\n",
      "tensor([3, 2, 3, 4])\n",
      "tensor([3, 1, 9, 0])\n",
      "tensor([9, 3, 6, 8])\n",
      "tensor([7, 0, 1, 0])\n",
      "tensor([5, 8, 2, 7])\n",
      "tensor([7, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 1])\n",
      "tensor([7, 4, 8, 1])\n",
      "tensor([5, 6, 5, 7])\n",
      "tensor([2, 8, 6, 3])\n",
      "tensor([3, 8, 6, 5])\n",
      "tensor([4, 0, 9, 1])\n",
      "tensor([7, 2, 9, 1])\n",
      "tensor([5, 1, 3, 2])\n",
      "tensor([2, 3, 0, 6])\n",
      "tensor([4, 3, 7, 6])\n",
      "tensor([9, 0, 4, 8])\n",
      "tensor([1, 4, 0, 6])\n",
      "tensor([1, 2, 6, 9])\n",
      "tensor([2, 2, 3, 5])\n",
      "tensor([5, 1, 0, 7])\n",
      "tensor([7, 9, 6, 2])\n",
      "tensor([9, 4, 7, 0])\n",
      "tensor([2, 3, 4, 0])\n",
      "tensor([0, 8, 8, 8])\n",
      "tensor([5, 1, 3, 7])\n",
      "tensor([4, 9, 8, 8])\n",
      "tensor([9, 0, 9, 8])\n",
      "tensor([9, 0, 2, 6])\n",
      "tensor([5, 6, 7, 4])\n",
      "tensor([7, 5, 4, 1])\n",
      "tensor([3, 5, 3, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 1, 2, 3])\n",
      "tensor([4, 6, 0, 1])\n",
      "tensor([2, 4, 5, 6])\n",
      "tensor([7, 8, 1, 7])\n",
      "tensor([2, 4, 1, 4])\n",
      "tensor([1, 4, 9, 6])\n",
      "tensor([8, 4, 5, 3])\n",
      "tensor([7, 8, 4, 3])\n",
      "tensor([3, 5, 6, 7])\n",
      "tensor([0, 6, 1, 6])\n",
      "tensor([8, 7, 0, 1])\n",
      "tensor([5, 0, 8, 5])\n",
      "tensor([0, 1, 5, 8])\n",
      "tensor([4, 2, 3, 9])\n",
      "tensor([7, 6, 9, 1])\n",
      "tensor([9, 0, 6, 7])\n",
      "tensor([1, 2, 3, 9])\n",
      "tensor([2, 4, 5, 5])\n",
      "tensor([3, 7, 5, 3])\n",
      "tensor([1, 8, 2, 2])\n",
      "tensor([3, 0, 2, 9])\n",
      "tensor([4, 9, 7, 0])\n",
      "tensor([2, 7, 4, 9])\n",
      "tensor([9, 2, 5, 9])\n",
      "tensor([8, 3, 8, 6])\n",
      "tensor([7, 0, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 0, 7, 2])\n",
      "tensor([6, 5, 5, 3])\n",
      "tensor([7, 8, 6, 6])\n",
      "tensor([6, 6, 4, 3])\n",
      "tensor([8, 8, 3, 0])\n",
      "tensor([1, 9, 0, 5])\n",
      "tensor([4, 1, 9, 1])\n",
      "tensor([2, 7, 0, 1])\n",
      "tensor([3, 8, 2, 9])\n",
      "tensor([2, 7, 4, 2])\n",
      "tensor([6, 5, 5, 9])\n",
      "tensor([9, 1, 1, 5])\n",
      "tensor([7, 6, 8, 2])\n",
      "tensor([9, 4, 3, 1])\n",
      "tensor([9, 0, 9, 3])\n",
      "tensor([6, 8, 7, 0])\n",
      "tensor([1, 0, 5, 8])\n",
      "tensor([2, 7, 7, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 2])\n",
      "tensor([1, 2, 1, 3])\n",
      "tensor([9, 9, 8, 5])\n",
      "tensor([3, 7, 0, 7])\n",
      "tensor([7, 5, 7, 9])\n",
      "tensor([9, 4, 7, 0])\n",
      "tensor([3, 4, 1, 5])\n",
      "tensor([8, 1, 4, 8])\n",
      "tensor([4, 1, 8, 6])\n",
      "tensor([6, 4, 6, 0])\n",
      "tensor([5, 5, 3, 3])\n",
      "tensor([5, 7, 2, 5])\n",
      "tensor([9, 6, 9, 2])\n",
      "tensor([6, 2, 1, 2])\n",
      "tensor([0, 8, 3, 8])\n",
      "tensor([3, 0, 8, 7])\n",
      "tensor([4, 9, 5, 0])\n",
      "tensor([9, 7, 0, 0])\n",
      "tensor([4, 6, 0, 9])\n",
      "tensor([1, 6, 2, 7])\n",
      "tensor([6, 8, 3, 5])\n",
      "tensor([2, 1, 8, 3])\n",
      "tensor([8, 6, 1, 0])\n",
      "tensor([2, 1, 4, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 7, 6, 4])\n",
      "tensor([7, 6, 2, 3])\n",
      "tensor([4, 8, 7, 8])\n",
      "tensor([6, 9, 8, 3])\n",
      "tensor([2, 2, 8, 4])\n",
      "tensor([8, 5, 6, 5])\n",
      "tensor([0, 2, 0, 1])\n",
      "tensor([1, 2, 9, 6])\n",
      "tensor([8, 2, 1, 0])\n",
      "tensor([6, 5, 2, 9])\n",
      "tensor([7, 5, 3, 9])\n",
      "tensor([3, 7, 1, 8])\n",
      "tensor([3, 8, 1, 9])\n",
      "tensor([5, 5, 0, 1])\n",
      "tensor([1, 9, 8, 2])\n",
      "tensor([6, 0, 4, 5])\n",
      "tensor([0, 3, 1, 8])\n",
      "tensor([6, 7, 5, 9])\n",
      "tensor([9, 3, 0, 3])\n",
      "tensor([1, 4, 4, 0])\n",
      "tensor([4, 9, 0, 1])\n",
      "tensor([2, 3, 5, 6])\n",
      "tensor([7, 8, 0, 1])\n",
      "tensor([2, 3, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([9, 7, 0, 9])\n",
      "tensor([0, 1, 5, 8])\n",
      "tensor([8, 0, 9, 3])\n",
      "tensor([2, 7, 8, 4])\n",
      "tensor([6, 1, 0, 4])\n",
      "tensor([9, 4, 2, 0])\n",
      "tensor([5, 0, 1, 6])\n",
      "tensor([9, 3, 2, 9])\n",
      "tensor([1, 6, 0, 1])\n",
      "tensor([1, 8, 7, 7])\n",
      "tensor([6, 3, 6, 0])\n",
      "tensor([7, 2, 4, 1])\n",
      "tensor([7, 0, 6, 7])\n",
      "tensor([1, 2, 5, 8])\n",
      "tensor([1, 8, 2, 8])\n",
      "tensor([7, 6, 8, 7])\n",
      "tensor([1, 6, 2, 9])\n",
      "tensor([3, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 8])\n",
      "tensor([9, 5, 7, 0])\n",
      "tensor([3, 1, 6, 8])\n",
      "tensor([4, 1, 5, 6])\n",
      "tensor([4, 2, 7, 8])\n",
      "tensor([1, 3, 4, 3])\n",
      "tensor([4, 7, 2, 0])\n",
      "tensor([5, 0, 1, 9])\n",
      "tensor([2, 3, 2, 3])\n",
      "tensor([5, 5, 7, 8])\n",
      "tensor([4, 9, 9, 7])\n",
      "tensor([1, 1, 9, 0])\n",
      "tensor([7, 8, 3, 4])\n",
      "tensor([8, 6, 3, 8])\n",
      "tensor([0, 9, 6, 2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([6, 2, 3, 8])\n",
      "tensor([9, 0, 7, 2])\n",
      "tensor([3, 4, 5, 5])\n",
      "tensor([2, 8, 5, 4])\n",
      "tensor([6, 6, 6, 7])\n",
      "tensor([9, 1, 8, 2])\n",
      "tensor([1, 5, 3, 4])\n",
      "tensor([7, 9, 4, 0])\n",
      "tensor([0, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([9, 0, 1, 3])\n",
      "tensor([1, 5, 1, 2])\n",
      "tensor([4, 9, 2, 4])\n",
      "tensor([6, 8, 0, 1])\n",
      "tensor([1, 9, 2, 6])\n",
      "tensor([6, 8, 7, 4])\n",
      "tensor([2, 9, 7, 0])\n",
      "tensor([2, 1, 0, 3])\n",
      "tensor([6, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 8])\n",
      "tensor([6, 5, 9, 7])\n",
      "tensor([0, 2, 3, 4])\n",
      "tensor([3, 8, 5, 1])\n",
      "tensor([5, 2, 3, 0])\n",
      "tensor([1, 2, 1, 3])\n",
      "tensor([2, 6, 5, 3])\n",
      "tensor([0, 7, 2, 7])\n",
      "tensor([4, 6, 4, 0])\n",
      "tensor([5, 9, 9, 8])\n",
      "tensor([9, 5, 3, 1])\n",
      "tensor([7, 4, 7, 6])\n",
      "tensor([5, 4, 0, 0])\n",
      "tensor([6, 6, 2, 0])\n",
      "tensor([6, 3, 7, 7])\n",
      "tensor([4, 4, 3, 9])\n",
      "tensor([2, 8, 9, 6])\n",
      "tensor([0, 9, 5, 3])\n",
      "tensor([8, 8, 7, 1])\n",
      "tensor([4, 0, 4, 8])\n",
      "tensor([5, 2, 3, 9])\n",
      "tensor([0, 1, 9, 1])\n",
      "tensor([5, 1, 7, 4])\n",
      "tensor([8, 6, 2, 1])\n",
      "tensor([6, 8, 8, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 7, 8, 9])\n",
      "tensor([1, 4, 5, 3])\n",
      "tensor([3, 0, 9, 5])\n",
      "tensor([4, 3, 0, 8])\n",
      "tensor([4, 6, 7, 0])\n",
      "tensor([7, 7, 1, 6])\n",
      "tensor([9, 1, 3, 6])\n",
      "tensor([2, 3, 8, 2])\n",
      "tensor([3, 8, 9, 5])\n",
      "tensor([8, 8, 7, 1])\n",
      "tensor([7, 1, 1, 0])\n",
      "tensor([3, 4, 2, 6])\n",
      "tensor([4, 7, 4, 2])\n",
      "tensor([7, 4, 2, 9])\n",
      "tensor([2, 7, 9, 2])\n",
      "tensor([1, 0, 6, 5])\n",
      "tensor([3, 4, 8, 5])\n",
      "tensor([9, 6, 9, 0])\n",
      "tensor([6, 3, 0, 8])\n",
      "tensor([1, 6, 0, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 2, 5, 1])\n",
      "tensor([6, 4, 3, 9])\n",
      "tensor([9, 0, 9, 7])\n",
      "tensor([1, 6, 4, 3])\n",
      "tensor([6, 2, 0, 9])\n",
      "tensor([8, 6, 5, 7])\n",
      "tensor([0, 0, 1, 7])\n",
      "tensor([4, 3, 2, 4])\n",
      "tensor([1, 3, 7, 6])\n",
      "tensor([4, 7, 7, 7])\n",
      "tensor([9, 8, 4, 3])\n",
      "tensor([8, 2, 8, 3])\n",
      "tensor([5, 8, 0, 5])\n",
      "tensor([4, 7, 1, 3])\n",
      "tensor([1, 7, 9, 6])\n",
      "tensor([2, 0, 9, 1])\n",
      "tensor([7, 3, 3, 9])\n",
      "tensor([1, 6, 4, 3])\n",
      "tensor([9, 8, 2, 1])\n",
      "tensor([8, 6, 4, 1])\n",
      "tensor([5, 5, 6, 5])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 6, 9])\n",
      "tensor([7, 0, 2, 3])\n",
      "tensor([4, 3, 8, 5])\n",
      "tensor([1, 3, 0, 1])\n",
      "tensor([2, 1, 3, 2])\n",
      "tensor([0, 7, 2, 6])\n",
      "tensor([4, 0, 5, 9])\n",
      "tensor([9, 8, 9, 5])\n",
      "tensor([3, 1, 7, 4])\n",
      "tensor([7, 0, 0, 6])\n",
      "tensor([6, 6, 3, 7])\n",
      "tensor([4, 2, 8, 9])\n",
      "tensor([8, 7, 1, 4])\n",
      "tensor([0, 4, 8, 5])\n",
      "tensor([2, 3, 9, 0])\n",
      "tensor([1, 9, 1, 5])\n",
      "tensor([1, 7, 6, 1])\n",
      "tensor([2, 1, 6, 8])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 0])\n",
      "tensor([1, 2, 3, 5])\n",
      "tensor([6, 7, 8, 1])\n",
      "tensor([0, 4, 5, 6])\n",
      "tensor([6, 3, 4, 4])\n",
      "tensor([2, 8, 1, 0])\n",
      "tensor([6, 4, 9, 7])\n",
      "tensor([2, 9, 2, 0])\n",
      "tensor([9, 3, 3, 9])\n",
      "tensor([1, 5, 2, 3])\n",
      "tensor([1, 6, 7, 3])\n",
      "tensor([7, 8, 4, 0])\n",
      "tensor([2, 4, 0, 2])\n",
      "tensor([4, 7, 8, 0])\n",
      "tensor([7, 0, 6, 9])\n",
      "tensor([3, 2, 4, 8])\n",
      "tensor([6, 0, 5, 7])\n",
      "tensor([5, 1, 0, 8])\n",
      "tensor([1, 6, 7, 2])\n",
      "tensor([9, 7, 9, 5])\n",
      "tensor([6, 5, 2, 6])\n",
      "tensor([2, 8, 1, 7])\n",
      "tensor([5, 5, 7, 3])\n",
      "tensor([5, 0, 1, 1])\n",
      "tensor([3, 8, 4, 9])\n",
      "tensor([4, 5, 1, 8])\n",
      "tensor([6, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 3, 5, 3])\n",
      "tensor([2, 9, 3, 2])\n",
      "tensor([1, 4, 5, 5])\n",
      "tensor([2, 3, 2, 1])\n",
      "tensor([3, 9, 7, 2])\n",
      "tensor([1, 2, 8, 9])\n",
      "tensor([1, 8, 8, 7])\n",
      "tensor([8, 1, 0, 0])\n",
      "tensor([6, 7, 7, 8])\n",
      "tensor([7, 5, 0, 6])\n",
      "tensor([1, 5, 7, 4])\n",
      "tensor([6, 1, 2, 5])\n",
      "tensor([0, 7, 9, 9])\n",
      "tensor([0, 3, 4, 4])\n",
      "tensor([8, 4, 1, 8])\n",
      "tensor([6, 5, 9, 0])\n",
      "tensor([0, 0, 3, 7])\n",
      "tensor([1, 6, 4, 6])\n",
      "tensor([0, 4, 5, 4])\n",
      "tensor([1, 3, 8, 6])\n",
      "tensor([3, 9, 9, 5])\n",
      "tensor([9, 3, 7, 8])\n",
      "tensor([5, 6, 4, 7])\n",
      "tensor([6, 2, 2, 0])\n",
      "tensor([9, 4, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([6, 4, 2, 6])\n",
      "tensor([4, 7, 5, 5])\n",
      "tensor([4, 7, 2, 9])\n",
      "tensor([3, 9, 3, 8])\n",
      "tensor([2, 0, 9, 5])\n",
      "tensor([6, 0, 1, 0])\n",
      "tensor([6, 5, 3, 5])\n",
      "tensor([3, 8, 0, 0])\n",
      "tensor([3, 4, 1, 5])\n",
      "tensor([3, 0, 8, 3])\n",
      "tensor([0, 6, 2, 7])\n",
      "tensor([8, 1, 7, 1])\n",
      "tensor([3, 8, 5, 4])\n",
      "tensor([2, 0, 9, 7])\n",
      "tensor([6, 7, 4, 1])\n",
      "tensor([6, 2, 6, 7])\n",
      "tensor([1, 9, 8, 0])\n",
      "tensor([6, 9, 4, 9])\n",
      "tensor([9, 6, 2, 3])\n",
      "tensor([7, 1, 9, 2])\n",
      "tensor([2, 5, 3, 7])\n",
      "tensor([8, 0, 1, 2])\n",
      "tensor([3, 4, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 7, 8])\n",
      "tensor([9, 0, 1, 7])\n",
      "tensor([8, 9, 8, 9])\n",
      "tensor([2, 6, 1, 3])\n",
      "tensor([5, 4, 8, 2])\n",
      "tensor([6, 4, 3, 4])\n",
      "tensor([5, 9, 2, 0])\n",
      "tensor([3, 9, 4, 9])\n",
      "tensor([7, 3, 8, 7])\n",
      "tensor([4, 4, 9, 8])\n",
      "tensor([5, 8, 2, 6])\n",
      "tensor([6, 2, 3, 1])\n",
      "tensor([3, 2, 7, 3])\n",
      "tensor([1, 9, 0, 1])\n",
      "tensor([1, 3, 5, 0])\n",
      "tensor([7, 8, 1, 5])\n",
      "tensor([1, 4, 6, 0])\n",
      "tensor([0, 4, 9, 1])\n",
      "tensor([6, 6, 9, 0])\n",
      "tensor([7, 6, 1, 1])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 7, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([0, 1, 2, 7])\n",
      "tensor([8, 6, 3, 9])\n",
      "tensor([7, 1, 9, 3])\n",
      "tensor([9, 6, 1, 7])\n",
      "tensor([2, 4, 4, 5])\n",
      "tensor([7, 0, 0, 1])\n",
      "tensor([6, 6, 8, 2])\n",
      "tensor([7, 7, 2, 4])\n",
      "tensor([2, 1, 6, 1])\n",
      "tensor([0, 6, 9, 8])\n",
      "tensor([3, 9, 6, 3])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 1, 6])\n",
      "tensor([8, 9, 9, 0])\n",
      "tensor([1, 2, 4, 4])\n",
      "tensor([3, 7, 4, 4])\n",
      "tensor([4, 0, 3, 8])\n",
      "tensor([7, 5, 8, 2])\n",
      "tensor([1, 7, 5, 3])\n",
      "tensor([8, 5, 2, 5])\n",
      "tensor([1, 1, 6, 2])\n",
      "tensor([1, 3, 8, 6])\n",
      "tensor([4, 2, 6, 2])\n",
      "tensor([5, 5, 0, 2])\n",
      "tensor([8, 0, 6, 8])\n",
      "tensor([1, 7, 9, 1])\n",
      "tensor([9, 2, 6, 7])\n",
      "tensor([6, 6, 8, 7])\n",
      "tensor([4, 9, 2, 1])\n",
      "tensor([3, 3, 0, 5])\n",
      "tensor([5, 8, 0, 3])\n",
      "tensor([7, 9, 7, 0])\n",
      "tensor([2, 7, 9, 1])\n",
      "tensor([7, 8, 0, 3])\n",
      "tensor([5, 3, 6, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 8, 9, 6])\n",
      "tensor([4, 2, 6, 4])\n",
      "tensor([7, 8, 9, 2])\n",
      "tensor([9, 3, 9, 3])\n",
      "tensor([0, 0, 1, 0])\n",
      "tensor([4, 2, 6, 3])\n",
      "tensor([5, 3, 0, 3])\n",
      "tensor([4, 1, 5, 3])\n",
      "tensor([0, 8, 3, 0])\n",
      "tensor([6, 1, 7, 8])\n",
      "tensor([0, 9, 2, 6])\n",
      "tensor([7, 1, 9, 6])\n",
      "tensor([9, 4, 9, 9])\n",
      "tensor([6, 7, 1, 2])\n",
      "tensor([5, 3, 7, 8])\n",
      "tensor([0, 1, 2, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 0, 1, 3])\n",
      "tensor([4, 7, 8, 9])\n",
      "tensor([7, 5, 5, 1])\n",
      "tensor([9, 9, 7, 1])\n",
      "tensor([0, 0, 5, 9])\n",
      "tensor([7, 1, 7, 2])\n",
      "tensor([2, 3, 6, 8])\n",
      "tensor([3, 2, 0, 0])\n",
      "tensor([6, 1, 7, 5])\n",
      "tensor([8, 6, 2, 9])\n",
      "tensor([4, 8, 8, 7])\n",
      "tensor([1, 0, 8, 7])\n",
      "tensor([7, 5, 8, 5])\n",
      "tensor([3, 4, 6, 1])\n",
      "tensor([1, 5, 5, 0])\n",
      "tensor([7, 2, 3, 6])\n",
      "tensor([4, 1, 2, 4])\n",
      "tensor([1, 5, 4, 2])\n",
      "tensor([0, 4, 8, 6])\n",
      "tensor([1, 9, 0, 2])\n",
      "tensor([5, 6, 9, 3])\n",
      "tensor([6, 3, 6, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 5])\n",
      "tensor([6, 7, 8, 1])\n",
      "tensor([0, 9, 5, 7])\n",
      "tensor([5, 1, 8, 6])\n",
      "tensor([9, 0, 4, 1])\n",
      "tensor([9, 3, 8, 4])\n",
      "tensor([4, 7, 0, 1])\n",
      "tensor([9, 2, 8, 7])\n",
      "tensor([8, 2, 5, 9])\n",
      "tensor([6, 0, 6, 5])\n",
      "tensor([5, 3, 3, 3])\n",
      "tensor([9, 8, 1, 1])\n",
      "tensor([0, 6, 1, 0])\n",
      "tensor([0, 6, 2, 1])\n",
      "tensor([1, 3, 2, 7])\n",
      "tensor([7, 8, 8, 7])\n",
      "tensor([8, 4, 6, 0])\n",
      "tensor([2, 0, 7, 0])\n",
      "tensor([3, 6, 8, 7])\n",
      "tensor([1, 5, 9, 9])\n",
      "tensor([3, 7, 2, 4])\n",
      "tensor([9, 4, 3, 6])\n",
      "tensor([2, 2, 5, 3])\n",
      "tensor([2, 5, 5, 9])\n",
      "tensor([4, 1, 7, 2])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 1, 0])\n",
      "tensor([1, 2, 7, 5])\n",
      "tensor([3, 4, 4, 0])\n",
      "tensor([0, 6, 9, 6])\n",
      "tensor([6, 5, 7, 2])\n",
      "tensor([3, 4, 4, 9])\n",
      "tensor([1, 4, 0, 7])\n",
      "tensor([9, 5, 7, 2])\n",
      "tensor([3, 1, 4, 4])\n",
      "tensor([0, 9, 9, 6])\n",
      "tensor([1, 8, 3, 3])\n",
      "tensor([7, 3, 9, 8])\n",
      "tensor([8, 4, 7, 7])\n",
      "tensor([6, 2, 1, 9])\n",
      "tensor([8, 7, 8, 8])\n",
      "tensor([7, 2, 2, 3])\n",
      "tensor([9, 3, 3, 5])\n",
      "tensor([5, 0, 7, 9])\n",
      "tensor([5, 6, 5, 1])\n",
      "tensor([4, 1, 1, 2])\n",
      "tensor([8, 2, 6, 1])\n",
      "tensor([5, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 9, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 8, 0])\n",
      "tensor([6, 0, 0, 2])\n",
      "tensor([3, 7, 9, 4])\n",
      "tensor([7, 1, 9, 1])\n",
      "tensor([7, 1, 4, 0])\n",
      "tensor([0, 1, 7, 5])\n",
      "tensor([7, 1, 3, 3])\n",
      "tensor([3, 1, 6, 9])\n",
      "tensor([7, 1, 3, 0])\n",
      "tensor([2, 6, 0, 8])\n",
      "tensor([9, 4, 3, 5])\n",
      "tensor([4, 8, 1, 5])\n",
      "tensor([9, 0, 6, 6])\n",
      "tensor([3, 8, 1, 4])\n",
      "tensor([7, 5, 2, 0])\n",
      "tensor([0, 1, 7, 8])\n",
      "tensor([9, 6, 8, 8])\n",
      "tensor([2, 3, 6, 1])\n",
      "tensor([2, 9, 5, 2])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([8, 9, 7, 4])\n",
      "tensor([6, 1, 4, 0])\n",
      "tensor([9, 9, 3, 7])\n",
      "tensor([8, 4, 7, 5])\n",
      "tensor([8, 5, 3, 2])\n",
      "tensor([2, 0, 5, 8])\n",
      "tensor([6, 0, 3, 8])\n",
      "tensor([1, 0, 3, 0])\n",
      "tensor([4, 7, 4, 9])\n",
      "tensor([2, 9, 5, 7])\n",
      "tensor([1, 7, 1, 6])\n",
      "tensor([6, 5, 6, 2])\n",
      "tensor([8, 7, 6, 4])\n",
      "tensor([9, 9, 5, 3])\n",
      "tensor([7, 4, 3, 0])\n",
      "tensor([4, 6, 6, 1])\n",
      "tensor([1, 3, 2, 1])\n",
      "tensor([0, 0, 1, 2])\n",
      "tensor([3, 4, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "tensor([7, 8, 0, 1])\n",
      "tensor([2, 3, 4, 7])\n",
      "tensor([8, 9, 0, 8])\n",
      "tensor([3, 9, 5, 5])\n",
      "tensor([2, 6, 8, 4])\n",
      "tensor([1, 7, 1, 2])\n",
      "tensor([3, 5, 6, 9])\n",
      "tensor([1, 1, 1, 2])\n",
      "tensor([1, 2, 0, 7])\n",
      "tensor([7, 5, 8, 2])\n",
      "tensor([9, 8, 6, 7])\n",
      "tensor([3, 4, 6, 8])\n",
      "tensor([7, 0, 4, 2])\n",
      "tensor([7, 7, 5, 4])\n",
      "tensor([3, 4, 2, 8])\n",
      "tensor([1, 5, 1, 0])\n",
      "tensor([2, 3, 3, 5])\n",
      "tensor([7, 0, 6, 8])\n",
      "tensor([6, 3, 9, 9])\n",
      "tensor([8, 2, 7, 7])\n",
      "tensor([1, 0, 1, 7])\n",
      "tensor([8, 9, 0, 1])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([6, 7, 8, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([7, 8, 9, 7])\n",
      "tensor([8, 6, 4, 1])\n",
      "tensor([9, 3, 8, 4])\n",
      "tensor([4, 7, 0, 1])\n",
      "tensor([9, 2, 8, 7])\n",
      "tensor([8, 2, 6, 0])\n",
      "tensor([6, 5, 3, 3])\n",
      "tensor([3, 9, 1, 4])\n",
      "tensor([0, 6, 1, 0])\n",
      "tensor([0, 6, 2, 1])\n",
      "tensor([1, 7, 7, 8])\n",
      "tensor([4, 6, 0, 7])\n",
      "tensor([0, 3, 6, 8])\n",
      "tensor([7, 1, 5, 2])\n",
      "tensor([4, 9, 4, 3])\n",
      "tensor([6, 4, 1, 7])\n",
      "tensor([2, 6, 5, 0])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([5, 6, 7, 8])\n",
      "tensor([9, 0, 1, 2])\n",
      "tensor([3, 4, 5, 6])\n",
      "Classifier accuracy on original test dataset: 0.971\n"
     ]
    }
   ],
   "source": [
    "print('Classifier accuracy on original test dataset:', accuracy(net, testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrvBEzmZLBeD"
   },
   "source": [
    "## Fast Gradient Sign Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5ZlWjqILygz"
   },
   "source": [
    "Here, we implement the Fast Gradient Sign Method, which takes in a batch of input images, their labels, a trained classifier, and the epsilon radius within which the perturbation should lie. This function should output the input image perturbed in the direction of the sign of the gradient with respect to the classifier's loss.\n",
    "\n",
    "(Note that the output is not guaranteed to lie in the valid range for images, since here pixel values must be in $[-1,1]$. You should use `torch.clamp` to fix the FGSM output to lie in the correct range.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CaSK1tjSLyg2"
   },
   "outputs": [],
   "source": [
    "def FGSM(x, labels, net, eps):\n",
    "    '''\n",
    "    Given an input image X and its corresponding labels\n",
    "    LABELS, as well as a classifier NET, returns X\n",
    "    perturbed by EPS using the fast gradient sign method.\n",
    "    '''\n",
    "    net.zero_grad()    # Zero out any gradients from before\n",
    "    x.requires_grad=True    # Keep track of gradients\n",
    "    out = net(x)    # Output of classifier\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(out, labels)   # Classifier's loss\n",
    "    loss.backward()\n",
    "    grads = x.grad.data    # Gradient of loss w/r/t input\n",
    "    perturbed_x = x + (eps * np.sign(grads))\n",
    "    perturbed_x = torch.clamp(perturbed_x, -1, 1)\n",
    "    return perturbed_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB8K0vMsLBeU"
   },
   "source": [
    "Let's see how well the classifier does when the input is adversarially perturbed using FGSM. Try this for $\\varepsilon\\in\\{0.05, 0.1,0.2,0.3, 0.4\\}$, and again remember to visualize the inputs with `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.05 # TODO: Try eps = 0.05, 0.1, 0.2, 0.3, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "dbS2KvG6Lyh6",
    "outputId": "da1fe90b-4789-416b-f26c-2e950e9c33ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier output: tensor([[ -5.4996, -15.1834,  -0.9374,  -1.5043, -22.2617,  -5.0610, -24.4297,\n",
      "           5.7185,  -2.9959,  -5.2328]])\n",
      "Classifier prediction: 7\n"
     ]
    }
   ],
   "source": [
    "# We are using the same sample input x as before.\n",
    "x.requires_grad = True\n",
    "x_prime = FGSM(x, labels, net, eps)\n",
    "imshow(x_prime[0,0].cpu())\n",
    "out = net(x_prime)\n",
    "\n",
    "print('Classifier output:', out.data)\n",
    "print('Classifier prediction:', torch.argmax(out).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64qakoWaLBec"
   },
   "source": [
    "We should evaluate the classifier's performance on FGSM-perturbed data by the same metric that we will later use in the primal adversarial problem. That is, for the classifier's output vector $\\vec{\\hat{z}}_3$, we want to compute\n",
    "$$\n",
    "\\vec{c}_j^\\top \\vec{\\hat{z}}_3\n",
    "$$\n",
    "where\n",
    "$$\\vec{c}_j={\\vec{y}_{\\text{true}}}-\\vec{e}_{j}$$\n",
    "for each $j\\in[10]$.\n",
    "\n",
    "Recall that \n",
    "$$\\vec{c}_j^\\top \\vec{\\hat{z}}_3=\\vec{\\hat{z}}_{3i_{\\text{true}}}-\\vec{\\hat{z}}_{3j},$$\n",
    "i.e. $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ is the difference between the classifier's confidence on the true class and the $j$th (incorrect) class. If $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ is positive for all incorrect $j$, then the classifier was not fooled by the adversarial perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "qpFjSe3ULBee",
    "outputId": "6256f017-d100-4f24-b932-ea6c67b8710e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.21806526184082\n",
      "1 20.901899337768555\n",
      "2 6.655935287475586\n",
      "3 7.222795486450195\n",
      "4 27.98021125793457\n",
      "5 10.779461860656738\n",
      "6 30.148168563842773\n",
      "8 8.714441299438477\n",
      "9 10.951316833496094\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    c = torch.zeros(10, 1).to(device)\n",
    "    if i != labels:\n",
    "        c[i] = -1\n",
    "        c[labels] = 1\n",
    "        print(i, (out @ c).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4JTyFqQLBeo"
   },
   "source": [
    "**Q: What do the $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores tell you about the robustness of the classifier to different values of epsilon? For a given input digit, which output categories have higher/lower scores? Why?**\n",
    "\n",
    "In this example, the true digit was a 7, so the outputs listed above are (confidence that number is 7  - confidence number is i) for all digits that are not 7. All the values are positive, which means the classifier was not fooled. Additionally, the specific values assigned to each number indicate that this is a fairly robust classifier. This is because for numbers that don't look anything like a 7 (j = 0, 1, 4, 6, 8, 9), $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ is high. On the other hand, for numbers that are more similar in shape to to a 7 (j= 2,3), $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ is closer to 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaGNmioNLyg_"
   },
   "source": [
    "Now that FGSM is defined, we can also measure a classifier's accuracy on a dataset where each input has been adversarially perturbed. That is, for each point in the original test dataset, we first perturb it using FGSM before feeding it to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ik9xXp3hLyhB"
   },
   "outputs": [],
   "source": [
    "def accuracy_on_FGSM(net, testloader, eps):\n",
    "    '''\n",
    "    Returns the accuracy of classifier NET on test\n",
    "    data from TESTLOADER that has been perturbed by\n",
    "    EPS using FSGM.\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        x, labels = data[0].to(device), data[1].to(device)\n",
    "        x_prime = FGSM(x, labels, net, eps)\n",
    "        outputs = net(x_prime)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "PDD_z76ALBew",
    "outputId": "01ccf72d-1bab-4ce7-ab00-d202779e0937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy on test dataset perturbed with FGSM: 0.931\n"
     ]
    }
   ],
   "source": [
    "print('Classifier accuracy on test dataset perturbed with FGSM:', accuracy_on_FGSM(net, testloader, 0.05))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dj-7r-oqLBe1"
   },
   "source": [
    "**Q: How does the classifier accuracy on data perturbed by FGSM compare to that on the original test dataset? How does this vary with epsilon?**\n",
    "\n",
    "$$\\begin{array}{|l|l|}\n",
    "\\hline\n",
    "\\epsilon & \\text{Classifier accuracy on test dataset perturbed with FGSM} \\\\ \\hline\n",
    "0.05    & 0.9182                                                  \\\\ \\hline\n",
    "0.1     & 0.8195                                                  \\\\ \\hline\n",
    "0.2     & 0.4749                                                  \\\\ \\hline\n",
    "0.3     & 0.1930                                                  \\\\ \\hline\n",
    "0.4     & 0.0681                                                  \\\\ \\hline\n",
    "\\end{array}$$\n",
    "\n",
    "Above is the table of the performance of classifier accuracy for the FGSM perturbed data. Even the highest accuracy among all epsilon was lower than than of regular gradient descent, which had an accuracy of 0.9687. From the results above, the accuracy seems to decrease as epsilon was increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDwEDxf9LBe7"
   },
   "source": [
    "## Dual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkVG-qEuLyhK"
   },
   "source": [
    "Here, we will implement the dual network. First, we write the function to compute upper and lower bounds for the dual network. This function should take an input image, the trained classifier, and an epsilon value, and return the tuple\n",
    "$$(\\vec{l},\\vec{u},S,S^-,S^+)$$\n",
    "where $\\vec{u}$ and $\\vec{l}$ are the upper and lower bounds, respectively, for the input to the ReLU layer, and $S^-,S^+,S$ are sets defined by\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&S:=\\{j\\in [n_2]\\mid l_{j}\\leq 0\\leq u_{j}\\}\\\\\n",
    "&S^{-}:=\\{j\\in [n_2]\\mid l_{j}\\leq u_{j}\\leq 0\\}\\\\\n",
    "&S^{+}:=\\{j\\in [n_2]\\mid 0\\leq l_{j}\\leq u_{j}\\}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "See Section 6 of the PDF for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0QHBHTHLyhO"
   },
   "outputs": [],
   "source": [
    "def dual_bounds(x, net, eps):\n",
    "    '''\n",
    "    Given a classifier NET, an input image X,\n",
    "    and the epsilon parameter EPS, returns the lower\n",
    "    and upper bounds L and U respectively, as well as\n",
    "    the corresponding sets S, S_MIN, S_PLUS.\n",
    "    '''\n",
    "    x = x[0].reshape(-1, 1)    # Reshape input to more convenient dimensions\n",
    "    W = [layer.weight for layer in net.layers]    # Array of network weights (W matrices)\n",
    "    b = [layer.bias.reshape(-1, 1) for layer in net.layers]    # Array of network biases (b vectors)\n",
    "    n = W[1].shape[1]    # Dimensionality of hidden layer\n",
    "    W_norms  = torch.norm(W[0], p=1, dim=1)\n",
    "    # print(W_norms)\n",
    "    # print(W_norms[0])\n",
    "    # W_norms = torch.stack(W_norms)\n",
    "    rshape = torch.reshape(eps*W_norms, (256,1))\n",
    "    u =  W[0]@x + b[0] + rshape\n",
    "    l = W[0]@x + b[0] - rshape\n",
    "    # print((W[0]@x).size())\n",
    "    # print(b[0].size())\n",
    "    # print(rshape.size())\n",
    "    S = [j for j in range(n) if (l[j] <= 0 and 0 <= u[j])]\n",
    "    S_min = [j for j in range(n) if (l[j] <= u[j] and u[j] <= 0)]\n",
    "    S_plus = [j for j in range(n) if (0 <= l[j] and l[j] <= u[j])]\n",
    "    return l, u, S, S_min, S_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaMhcqTvLyhX"
   },
   "source": [
    "Given the tuple $(l,u,S,S^-,S^+)$, we are ready to calculate the dual objective itself. This function should take in an input image, the classifier, a vector $c$, and the $(l,u,S,S^-,S^+)$ from the previous function in order to output \n",
    "$$\n",
    "d^*(\\vec{x},\\vec{c})= \n",
    "-\\vec{\\hat{\\nu}}_1^\\top \\vec{x}-\\varepsilon\\|\\vec{\\hat{\\nu}}_1\\|_1-\\sum_{i=1}^{2}\\vec{\\nu}_{i+1}^\\top \\vec{b}_i+\\sum_{j\\in S\\\n",
    "}l_{j}\\text{ReLU}(\\nu_{2j})\n",
    "$$\n",
    "\n",
    "Where the $\\vec{\\nu}$ vectors are computed as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\vec{\\nu}_3=-\\vec{c}\\\\\n",
    "&\\vec{\\hat{\\nu}}_2=W_2^\\top \\vec{\\nu}_{3}\\\\\n",
    "&\\nu_{2j}=0 && \\forall j\\in S^-\\\\\n",
    "&\\nu_{2j}=\\hat{\\nu}_{2j} && \\forall j\\in S^+\\\\\n",
    "&\\nu_{2j}=\\dfrac{u_{j}}{u_{j}-l_{j}}\\hat{\\nu}_{2j} && \\forall j\\in S\\\\\n",
    "&\\vec{\\hat{\\nu}}_1=W_1^\\top \\vec{\\nu_{2}}\n",
    "&\\end{aligned}.\n",
    "$$\n",
    "\n",
    "Again, see Section 6 of the PDF for more details.\n",
    "\n",
    "One efficient way to compute $\\vec{\\nu}_2$ is to rewrite it as\n",
    "$$\\vec{\\nu}_2= D\\vec{\\hat{\\nu}}_2,$$\n",
    "where $D$ is a diagonal matrix defined  by\n",
    "$$\n",
    "D_{jj}=\\begin{cases}\n",
    "0 & j\\in S^-\\\\\n",
    "\\hat{\\nu}_{2j} & j\\in S^+\\\\\n",
    "\\dfrac{u_{j}}{u_{j}-l_{j}}\\hat{\\nu}_{2j} & j\\in S.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chl5lue0Lyha"
   },
   "outputs": [],
   "source": [
    "# Constructs the diagonal D matrix from the S sets, n (the dimensionality\n",
    "# of the hidden layer), u, and l.\n",
    "def StoD(S_min, S_plus, S, n, u, l):\n",
    "    '''\n",
    "    Given upper and lower bounds U and L, as well\n",
    "    as the corresponding sets S_MIN, S_PLUS, and S,\n",
    "    as well as the dimension of the hidden layer N,\n",
    "    returns the corresponding diagonal matrix D.\n",
    "    '''\n",
    "    d = []\n",
    "    for j in range(n):\n",
    "        if j in S:\n",
    "            d.append((u[j] / (u[j] - l[j])).item())\n",
    "        elif j in S_plus:\n",
    "            d.append(1)\n",
    "        elif j in S_min:\n",
    "            d.append(0)\n",
    "        else:\n",
    "            assert False, 'StoD error.'\n",
    "    return torch.diag(torch.Tensor(d)).to(device)\n",
    "\n",
    "def dual_forward(x, net, c, eps, l, u, S, S_min, S_plus):\n",
    "    '''\n",
    "    Calculates the dual objective for classifier NET with input X\n",
    "    and dual input C and epsilon parameter S. Depends on lower\n",
    "    and upper bounds L and U, as well as the corresponding sets\n",
    "    S, S_MIN, S_PLUS.\n",
    "    '''\n",
    "    x = x[0].reshape(-1, 1)    # Reshape input to more convenient dimensions\n",
    "    W = [layer.weight for layer in net.layers]    # Array of network weights (W matrices)\n",
    "    b = [layer.bias.reshape(-1, 1) for layer in net.layers]    # Array of network biases (b vectors)\n",
    "    n = W[1].shape[1]    # Dimensionality of hidden layer\n",
    "    D = StoD(S_min, S_plus, S, n, u, l)\n",
    "\n",
    "    \n",
    "    v_3 = -c\n",
    "    #print(v_3)\n",
    "    v_2 = D @ (W[1].T @ v_3)\n",
    "    v_1 = W[0].T @ v_2\n",
    "\n",
    "    # v_3 = torch.reshape(v_3, (-1, 1))\n",
    "    # v_2 = torch.reshape(v_2, (-1, 1))\n",
    "    # v_1 = torch.reshape(v_1, (-1, 1))\n",
    "\n",
    "    # print(\"c shape : \" + str(c.size()), \"x shape : \" + str(x.size()))\n",
    "    # print(\"v1 shape : \" + str(v_1.size()), \"v2 shape : \" + str(v_2.size()), \"v3 shape : \" + str(v_3.size()))\n",
    "    non_relu_t1 = -v_1.T @ x\n",
    "    non_relu_t2 = eps * torch.norm(v_1, p=1)\n",
    "    non_relu_t3 = (v_2.T @ b[0] + v_3.T @ b[1])\n",
    "\n",
    "    \n",
    "    non_relu_terms = (non_relu_t1 - non_relu_t2 - non_relu_t3)\n",
    "\n",
    "    \n",
    "    # print(\"W0 shape : \" + str(W[0].size()), \"v2 shape : \" + str(v_2.size()), \"v3 shape : \" + str(v_3.size()))\n",
    "    # print(non_relu_terms)\n",
    "    if len(non_relu_terms.shape) != 2:\n",
    "        non_relu_terms = non_relu_terms.item()\n",
    "    else:\n",
    "        non_relu_terms = non_relu_terms.squeeze()\n",
    "    relu = nn.ReLU()\n",
    "    relu_term = sum([l[j] * relu(v_2[j]) for j in S])\n",
    "    # print(non_relu_terms)\n",
    "    # print(relu_term)\n",
    "    \n",
    "    objective = non_relu_terms + relu_term\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HagySRiNLyhu"
   },
   "source": [
    "Now, we can use the dual network to check the robustness of the network we just trained on sample input images. We can do this for \n",
    "$$\\vec{c}_j={\\vec{y}_{\\text{true}}}-\\vec{e}_{j}$$\n",
    "for each $j\\in[10]$.\n",
    "\n",
    "The output is a vector where the $j$th element is the difference between the model's confidence in the true class and the $j$th class; if $d^*(\\vec{x},\\vec{c}_j)$ is nonnegative for every $j\\in[10]$, then we know the model is robust to perturbations of size $\\varepsilon$. See Section 8 of the PDF for more details.\n",
    "\n",
    "Try running the following block of code for different values of $\\varepsilon\\in\\{0.05, 0.1, 0.2, 0.3, 0.4\\}$, and compare the robustness guarantees here with the classifier's performance on the FGSM data from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.2 # TODO: Try eps = 0.05, 0.1, 0.2, 0.3, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "WY6TfL2GLyhw",
    "outputId": "41886f00-c9f7-4f6d-b227-1bb5fe647a19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -27.815792083740234\n",
      "1 -16.92518424987793\n",
      "2 -31.02103614807129\n",
      "3 -30.744319915771484\n",
      "4 -18.53803062438965\n",
      "5 -34.180416107177734\n",
      "6 -17.7916316986084\n",
      "8 -28.69359588623047\n",
      "9 -25.606775283813477\n"
     ]
    }
   ],
   "source": [
    "# We are still using the same sample input x as before.\n",
    "l, u, S, S_min, S_plus = dual_bounds(x, net, eps)\n",
    "\n",
    "# Here, we loop through each column c_j defined above, and output the \n",
    "# objective value for the dual function with input c.\n",
    "for i in range(10):\n",
    "    c = torch.zeros(10, 1).to(device)\n",
    "    if i != labels:\n",
    "        c[i] = -1\n",
    "        c[labels] = 1\n",
    "        print(i, dual_forward(x, net, c, eps, l, u, S, S_min, S_plus).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v--Zs9ELLyiB"
   },
   "source": [
    "**Q: What do the dual network outputs tell you about the robustness of the classifier? How does this compare to the classifier's performance (in particular, the $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ scores) on FGSM outputs? How does your answer change with epsilon?**\n",
    "\n",
    "For epsilon=0.05, no elements of $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ are negative, which indicates that the actual class remained the predicted class. However, for epsilon=0.2, multiple  elements of $\\vec{c}_j^\\top \\vec{\\hat{z}}_3$ were negative, which indicates that the network was more confident that the number belonged to a class that was not the true class. It seems that the network is more robust for lower epsilon, but not so much as we increase epsilon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dr3xSI7EMv4l"
   },
   "source": [
    "**Q: Suppose you have a deep neural classifier that you want to defend against adversarial attacks. That is, you want to detect and discard any input images that were possibly adversarially perturbed. How might you do this with the robustness certificate you have implemented?**\n",
    "\n",
    "We can compare the output of the model that included FGSM modified training examples and the model that didn't include FGSM modified training examples. If the adversarial perturbation is within the epsilon ball, we can observe the difference in output from the two models and then discard the perturbation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s--Ae8VpLyiN"
   },
   "source": [
    "## Robust training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LohSkAUMLBfa"
   },
   "source": [
    "The following function should implement the robust loss from section A of the PDF. This loss is an upper bound on the worst-case loss within an $\\epsilon$ ball of the original training input. Thus, training using this new loss should result in a classifier that is more robust than one trained on the original cross-entropy loss.\n",
    "\n",
    "There are no mandatory questions here, but feel free to experiment with this robust training, and compare the performance here (measured by the dual objective certificate, as well as original/FGSM accuracy) to that of the original. You can also try training a model using the original loss first, then fine-tuning with the robust loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTv9zjuqLyiQ"
   },
   "outputs": [],
   "source": [
    "def robust_loss(x, label, net, eps, criterion):\n",
    "    '''\n",
    "    Given a batch of input images X, its corresponding lables LABEL,\n",
    "    the classifier NET, epsilon value EPS, and original loss\n",
    "    function CRITERION, returns the robust loss of NET w/r/t\n",
    "    the original loss function, on the input image.\n",
    "    '''\n",
    "    l, u, S, S_min, S_plus = dual_bounds(x, net, eps)\n",
    "    # We assume there are 10 classes.\n",
    "    e_y = torch.zeros(10, 1)\n",
    "    e_y[label] = 1 #causes J vector to be all 0\n",
    "    c = e_y @ torch.ones(1, 10) - torch.eye(10)\n",
    "    #J = torch.zeros(10, 1)\n",
    "    \n",
    "    #J = [dual_forward(x, net, c[:, col].reshape(10, 1), eps, l, u, S, S_min, S_plus) for col in range(c.size()[1])]\n",
    "    # J = []\n",
    "\n",
    "    # for col in range(c.size()[1]):\n",
    "    #     reshaped_c = c[:, col].reshape(10, 1)\n",
    "    #     # print(col)\n",
    "    #     J[col] = dual_forward(x, net, reshaped_c, eps, l, u, S, S_min, S_plus)\n",
    "    # J = torch.stack(J)\n",
    "    J = dual_forward(x, net, c, eps, l, u, S, S_min, S_plus)\n",
    "\n",
    "    # print(\"FORWARD\", dual_forward(x, net, c, eps, l, u, S, S_min, S_plus))\n",
    "    #print(label.unsqueeze(0))\n",
    "    #label_onehot = torch.nn.functional.one_hot(label, num_classes=10)\n",
    "    #return criterion(-J, label_onehot.unsqueeze(0).squeeze(1))\n",
    "    label_zeros = torch.zeros(10, 1)\n",
    "    label_zeros[label] = 1\n",
    "    label = label_zeros\n",
    "    # print(-J)\n",
    "    # CROSS ENTROPY NOT CALCULATING LOSS CORRECTLY EVEN WITH -J AND LABEL WITH VALUES != 0\n",
    "    #print(criterion(-J, label))\n",
    "    #print(-J)\n",
    "    # print(label)\n",
    "    return criterion(-J.squeeze(), label.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nj_VkNaNLyiY"
   },
   "outputs": [],
   "source": [
    "def robust_train(net, criterion, trainloader, eps, lr=0.001):\n",
    "    '''\n",
    "    Trains the classifier NET using the robust version\n",
    "    of the original loss function CRITERION with paramater EPS,\n",
    "    using training data from TRAINLOADER and with learning rate LR.\n",
    "    \n",
    "    Note that we half the learning rate each epoch.\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        for i , data in enumerate(trainloader, 0):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.5 ** (epoch)\n",
    "\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            for k in range(inputs.shape[0]):\n",
    "                x = inputs[k]\n",
    "                label = labels[k]\n",
    "                loss += robust_loss(x, label, net, eps, criterion)\n",
    "            #loss += robust_loss(inputs.squeeze(), labels, net, eps, criterion)\n",
    "            # print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i % 500 == 0:\n",
    "                print('Epoch', epoch, 'Iter:', i, 'Loss', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_net = Net()\n",
    "robust_net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# robust_train(net, criterion, trainloader, eps)\n",
    "robust_net  = torch.load(\"robust_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier output: tensor([[ -6.9609, -17.2949,  -2.1810,  -2.4582, -22.3228,  -5.8204, -26.3086,\n",
      "           6.9209,  -4.2982,  -5.1956]])\n",
      "Classifier prediction: 7\n"
     ]
    }
   ],
   "source": [
    "x, labels = next(test_iter)\n",
    "x = x[0].unsqueeze(0)\n",
    "labels = labels[0].unsqueeze(0)\n",
    "imshow(x[0,0])\n",
    "\n",
    "x = x.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "out = net(x).data\n",
    "print('Classifier output:', out)\n",
    "print('Classifier prediction:', torch.argmax(out).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.881789207458496\n",
      "1 24.215795516967773\n",
      "2 9.101949691772461\n",
      "3 9.379127502441406\n",
      "4 29.243741989135742\n",
      "5 12.74131965637207\n",
      "6 33.229549407958984\n",
      "8 11.219161033630371\n",
      "9 12.116507530212402\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    c = torch.zeros(10, 1).to(device)\n",
    "    if i != labels:\n",
    "        c[i] = -1\n",
    "        c[labels] = 1\n",
    "        print(i, (out @ c).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primal Accuracy 0.971 Primal Accuracy on FGSM 0.931\n",
      "Robust Accuracy 0.9532 Robust Accuracy on FGSM 0.8948\n"
     ]
    }
   ],
   "source": [
    "print(\"Primal Accuracy\", accuracy(net, testloader), \"Primal Accuracy on FGSM\", accuracy_on_FGSM(net, testloader, 0.05))\n",
    "print(\"Robust Accuracy\", accuracy(robust_net, testloader), \"Robust Accuracy on FGSM\", accuracy_on_FGSM(robust_net, testloader, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_and_precision(net, testloader):\n",
    "    '''\n",
    "    Returns the accuracy of classifier NET\n",
    "    on test data from TESTLOADER.\n",
    "    '''\n",
    "\n",
    "    accuracy_mat = [[0 for j in range(10)] for i in range(10)]\n",
    "    false_negative = [0] * 10\n",
    "    false_positive = [0] * 10\n",
    "    true_positive = [0] * 10\n",
    "    #accuracy_mat[predicted][real]\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device).tolist()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = predicted.tolist()\n",
    "\n",
    "            for i in range(len(predicted)):\n",
    "                accuracy_mat[predicted[i]][labels[i]] +=1\n",
    "\n",
    "        for i in range(len(accuracy_mat)):\n",
    "            fn_curr = 0\n",
    "            fp_curr = 0 \n",
    "            for j in range(len(accuracy_mat[0])):\n",
    "                if i != j:\n",
    "                    fn_curr+= accuracy_mat[j][i]\n",
    "                    fp_curr += accuracy_mat[i][j]\n",
    "            false_negative[i] = fn_curr\n",
    "            false_positive[i] = fp_curr\n",
    "        \n",
    "        for i in range(len(accuracy_mat)):\n",
    "            true_positive[i] = accuracy_mat[i][i]\n",
    "        \n",
    "\n",
    "        false_negative = np.array(false_negative)\n",
    "        false_positive = np.array(false_positive)\n",
    "        true_positive = np.array(true_positive)\n",
    "\n",
    "        recall = true_positive/(true_positive + false_negative)\n",
    "        precision = true_positive/(true_positive + false_positive)\n",
    "        return recall, precision\n",
    "    \n",
    "    # return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98877551 0.99207048 0.98449612 0.94356436 0.96028513 0.9529148\n",
      " 0.93110647 0.94357977 0.9486653  0.88107037] [0.96130952 0.96075085 0.88966725 0.96555218 0.9345887  0.94654788\n",
      " 0.9900111  0.95378564 0.96350365 0.98015436]\n"
     ]
    }
   ],
   "source": [
    "robust_recall, robust_precision = recall_and_precision(robust_net, testloader)\n",
    "print(robust_recall, robust_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98571429 0.98678414 0.98062016 0.96435644 0.97454175 0.97869955\n",
      " 0.97912317 0.96303502 0.97433265 0.92269574] [0.97085427 0.98852604 0.97120921 0.97302697 0.96764408 0.96251378\n",
      " 0.97202073 0.96774194 0.95185557 0.98206751]\n"
     ]
    }
   ],
   "source": [
    "recall, precision = recall_and_precision(net, testloader)\n",
    "print(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torch_impl_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "080f0e9e20374c8b9d0772c207d40204": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d2ab5e4e4634c2d84445dcb59e63093": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0ffb65b8fcd64017a1575ef5c6fb6783": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e0fc65863e247bba684aa570176e47e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9b0d7cc1d4a84b32ad704d0f92aaf7c2",
       "IPY_MODEL_359ca0eaed76461b8920085a62f10151"
      ],
      "layout": "IPY_MODEL_0ffb65b8fcd64017a1575ef5c6fb6783"
     }
    },
    "2dfa9272bd3a454582ebcd023d814301": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cdd60a9989c4e2fba367aa0fc23db04",
      "placeholder": "​",
      "style": "IPY_MODEL_77a3b32f508c46f4a5bae2a29bbfc4f2",
      "value": " 8192/? [00:06&lt;00:00, 1348.53it/s]"
     }
    },
    "359ca0eaed76461b8920085a62f10151": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_080f0e9e20374c8b9d0772c207d40204",
      "placeholder": "​",
      "style": "IPY_MODEL_7cb630c6d3784c0ba705b39311a36690",
      "value": " 0/28881 [00:00&lt;?, ?it/s]"
     }
    },
    "3ce16927200e4dfbba645b52ede3be15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51fab2724f5240f2a197da36bfb5d37f",
      "placeholder": "​",
      "style": "IPY_MODEL_7f3be4825b3942bfbd15404ae2826968",
      "value": " 9920512/? [00:20&lt;00:00, 1533441.80it/s]"
     }
    },
    "40781e910ad14961b70299654d08af57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "410b4797b4eb474185b6e9e8768efe90": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "443bc19134b346e282b58b81de72ee9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d51c1aaaee7e40eb9a6946ee964f26db",
       "IPY_MODEL_75a9df895ea94bb787ead957f9b540c9"
      ],
      "layout": "IPY_MODEL_be2ab404919947b6bec6e47d8ef2293e"
     }
    },
    "48f34dff73514ae58be4a78b897605de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51fab2724f5240f2a197da36bfb5d37f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cdd60a9989c4e2fba367aa0fc23db04": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68fb67ba49274e2381586dfa12d4a00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "73155d071971464cac0ed23138cde635": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75a9df895ea94bb787ead957f9b540c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad74039e867d489fbcc6c9d8ff34706c",
      "placeholder": "​",
      "style": "IPY_MODEL_73155d071971464cac0ed23138cde635",
      "value": " 1654784/? [00:06&lt;00:00, 244349.52it/s]"
     }
    },
    "77a3b32f508c46f4a5bae2a29bbfc4f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7cb630c6d3784c0ba705b39311a36690": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f3be4825b3942bfbd15404ae2826968": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86cdc4424b24473a8d571d2160ee7576": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a08a24593a2422985302484dc4594d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8c6d1f7d352a4c089e4ae601a73c1068": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_410b4797b4eb474185b6e9e8768efe90",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a08a24593a2422985302484dc4594d1",
      "value": 1
     }
    },
    "9601fc4be35543a784d4231a2de31edb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b0d7cc1d4a84b32ad704d0f92aaf7c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c75be203b59b4c599fd51b44b5359236",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d2ab5e4e4634c2d84445dcb59e63093",
      "value": 0
     }
    },
    "9d5649b6391e44f5ad266c65fe71ec8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de997021a80b4943b20c5518910ea387",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68fb67ba49274e2381586dfa12d4a00a",
      "value": 1
     }
    },
    "ad74039e867d489fbcc6c9d8ff34706c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bde4879694234dc087cc6ef3a8f999e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d5649b6391e44f5ad266c65fe71ec8e",
       "IPY_MODEL_2dfa9272bd3a454582ebcd023d814301"
      ],
      "layout": "IPY_MODEL_86cdc4424b24473a8d571d2160ee7576"
     }
    },
    "be2ab404919947b6bec6e47d8ef2293e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c33f5dd2c1f443f1b771f0c46054eebf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c6d1f7d352a4c089e4ae601a73c1068",
       "IPY_MODEL_3ce16927200e4dfbba645b52ede3be15"
      ],
      "layout": "IPY_MODEL_9601fc4be35543a784d4231a2de31edb"
     }
    },
    "c75be203b59b4c599fd51b44b5359236": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d51c1aaaee7e40eb9a6946ee964f26db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48f34dff73514ae58be4a78b897605de",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40781e910ad14961b70299654d08af57",
      "value": 1
     }
    },
    "de997021a80b4943b20c5518910ea387": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
